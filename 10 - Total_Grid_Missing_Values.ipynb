{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad544928-964f-47cb-85d8-9b1525401f29",
   "metadata": {},
   "source": [
    "# Grid Forecasting: Missing Values\n",
    "In the previous notebooks, analysis was done only with respect to Zone 1. Here, Time Series Regression is used to perform prediction for all zones simultaneously.\n",
    "> Predictions are done to fill missing values (best estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015337fa-c2db-42c9-989d-a4443c987c88",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729dcf4-cf1f-4bb4-b5d8-6ba03facb1de",
   "metadata": {},
   "source": [
    "### Defining Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e72677f-ad5f-496d-bbdb-7344ba7f9821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>load</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>16853.0</td>\n",
       "      <td>2004-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14850</th>\n",
       "      <td>10</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>23339.0</td>\n",
       "      <td>2004-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16500</th>\n",
       "      <td>11</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>90700.0</td>\n",
       "      <td>2004-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28050</th>\n",
       "      <td>18</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>200946.0</td>\n",
       "      <td>2004-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>7</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>2004-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       zone_id  year  month  day   hour      load            timestamp\n",
       "0            1  2004      1    1  00:30   16853.0  2004-01-01 00:30:00\n",
       "14850       10  2004      1    1  00:30   23339.0  2004-01-01 00:30:00\n",
       "16500       11  2004      1    1  00:30   90700.0  2004-01-01 00:30:00\n",
       "28050       18  2004      1    1  00:30  200946.0  2004-01-01 00:30:00\n",
       "9900         7  2004      1    1  00:30  136233.0  2004-01-01 00:30:00"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# Loading the data\n",
    "load_long = pd.read_csv(r\"C:\\Users\\singh\\Desktop\\TUD (All Semesters)\\Courses - Semester 6 (TU Dresden)\\Thesis Work\\Exploratory Code\\load_history_long.csv\").sort_values(by = \"timestamp\")\n",
    "load_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cfefb8-4b62-4e08-897b-567994d430e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01 00:30:00</th>\n",
       "      <td>16853.0</td>\n",
       "      <td>126259.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>6829.0</td>\n",
       "      <td>133088.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>3124.0</td>\n",
       "      <td>75243.0</td>\n",
       "      <td>23339.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65970.0</td>\n",
       "      <td>28752.0</td>\n",
       "      <td>30645.0</td>\n",
       "      <td>200946.0</td>\n",
       "      <td>82298.0</td>\n",
       "      <td>79830.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 01:30:00</th>\n",
       "      <td>16450.0</td>\n",
       "      <td>123313.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>6596.0</td>\n",
       "      <td>129909.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>67368.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64600.0</td>\n",
       "      <td>27851.0</td>\n",
       "      <td>30461.0</td>\n",
       "      <td>195835.0</td>\n",
       "      <td>79827.0</td>\n",
       "      <td>77429.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 02:30:00</th>\n",
       "      <td>16517.0</td>\n",
       "      <td>119192.0</td>\n",
       "      <td>128608.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>6525.0</td>\n",
       "      <td>125717.0</td>\n",
       "      <td>128608.0</td>\n",
       "      <td>2953.0</td>\n",
       "      <td>64050.0</td>\n",
       "      <td>21376.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63843.0</td>\n",
       "      <td>27631.0</td>\n",
       "      <td>30197.0</td>\n",
       "      <td>194093.0</td>\n",
       "      <td>77728.0</td>\n",
       "      <td>75558.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 03:30:00</th>\n",
       "      <td>16873.0</td>\n",
       "      <td>117507.0</td>\n",
       "      <td>126791.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>6654.0</td>\n",
       "      <td>124162.0</td>\n",
       "      <td>126791.0</td>\n",
       "      <td>2914.0</td>\n",
       "      <td>63861.0</td>\n",
       "      <td>21335.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64023.0</td>\n",
       "      <td>27986.0</td>\n",
       "      <td>30264.0</td>\n",
       "      <td>194708.0</td>\n",
       "      <td>76433.0</td>\n",
       "      <td>75709.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 04:30:00</th>\n",
       "      <td>17064.0</td>\n",
       "      <td>118343.0</td>\n",
       "      <td>127692.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>6977.0</td>\n",
       "      <td>125320.0</td>\n",
       "      <td>127692.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>75852.0</td>\n",
       "      <td>21564.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65679.0</td>\n",
       "      <td>29160.0</td>\n",
       "      <td>30907.0</td>\n",
       "      <td>202458.0</td>\n",
       "      <td>78172.0</td>\n",
       "      <td>77475.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2004-01-01 00:30:00  16853.0  126259.0  136233.0  484.0  6829.0  133088.0   \n",
       "2004-01-01 01:30:00  16450.0  123313.0  133055.0  457.0  6596.0  129909.0   \n",
       "2004-01-01 02:30:00  16517.0  119192.0  128608.0  450.0  6525.0  125717.0   \n",
       "2004-01-01 03:30:00  16873.0  117507.0  126791.0  448.0  6654.0  124162.0   \n",
       "2004-01-01 04:30:00  17064.0  118343.0  127692.0  444.0  6977.0  125320.0   \n",
       "\n",
       "zone_id                     7       8        9       10  ...       15  \\\n",
       "timestamp                                                ...            \n",
       "2004-01-01 00:30:00  136233.0  3124.0  75243.0  23339.0  ...  65970.0   \n",
       "2004-01-01 01:30:00  133055.0  2956.0  67368.0  22100.0  ...  64600.0   \n",
       "2004-01-01 02:30:00  128608.0  2953.0  64050.0  21376.0  ...  63843.0   \n",
       "2004-01-01 03:30:00  126791.0  2914.0  63861.0  21335.0  ...  64023.0   \n",
       "2004-01-01 04:30:00  127692.0  3221.0  75852.0  21564.0  ...  65679.0   \n",
       "\n",
       "zone_id                   16       17        18       19       20  year  \\\n",
       "timestamp                                                                 \n",
       "2004-01-01 00:30:00  28752.0  30645.0  200946.0  82298.0  79830.0  2004   \n",
       "2004-01-01 01:30:00  27851.0  30461.0  195835.0  79827.0  77429.0  2004   \n",
       "2004-01-01 02:30:00  27631.0  30197.0  194093.0  77728.0  75558.0  2004   \n",
       "2004-01-01 03:30:00  27986.0  30264.0  194708.0  76433.0  75709.0  2004   \n",
       "2004-01-01 04:30:00  29160.0  30907.0  202458.0  78172.0  77475.0  2004   \n",
       "\n",
       "zone_id              month  day  hour  \n",
       "timestamp                              \n",
       "2004-01-01 00:30:00      1    1     0  \n",
       "2004-01-01 01:30:00      1    1     1  \n",
       "2004-01-01 02:30:00      1    1     2  \n",
       "2004-01-01 03:30:00      1    1     3  \n",
       "2004-01-01 04:30:00      1    1     4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to Wide Format\n",
    "load_wide = load_long.pivot_table(\n",
    "    index='timestamp',      # The column to use as the index\n",
    "    columns='zone_id',  # The column whose unique values will become the new column names\n",
    "    values='load'    # The column to use for the values in the new DataFrame.\n",
    ").sort_values(by=\"timestamp\")\n",
    "\n",
    "# Converting string to datetime\n",
    "from datetime import datetime\n",
    "load_wide.index = pd.to_datetime(load_wide.index)\n",
    "load_wide.index[0]\n",
    "\n",
    "# Segregating temporal information\n",
    "load_wide['year'] = load_wide.index.year\n",
    "load_wide['month'] = load_wide.index.month\n",
    "load_wide['day'] = load_wide.index.day\n",
    "load_wide['hour'] = load_wide.index.hour\n",
    "\n",
    "load_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8e9d12-a890-4217-ad06-821a4546459f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01 00:30:00</th>\n",
       "      <td>9.732284</td>\n",
       "      <td>11.746091</td>\n",
       "      <td>11.822122</td>\n",
       "      <td>6.182085</td>\n",
       "      <td>8.828934</td>\n",
       "      <td>11.798766</td>\n",
       "      <td>11.822122</td>\n",
       "      <td>8.046870</td>\n",
       "      <td>11.228478</td>\n",
       "      <td>10.057881</td>\n",
       "      <td>...</td>\n",
       "      <td>11.096955</td>\n",
       "      <td>10.266463</td>\n",
       "      <td>10.330225</td>\n",
       "      <td>12.210791</td>\n",
       "      <td>11.318102</td>\n",
       "      <td>11.287655</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 01:30:00</th>\n",
       "      <td>9.708081</td>\n",
       "      <td>11.722481</td>\n",
       "      <td>11.798518</td>\n",
       "      <td>6.124683</td>\n",
       "      <td>8.794219</td>\n",
       "      <td>11.774589</td>\n",
       "      <td>11.798518</td>\n",
       "      <td>7.991592</td>\n",
       "      <td>11.117925</td>\n",
       "      <td>10.003333</td>\n",
       "      <td>...</td>\n",
       "      <td>11.075970</td>\n",
       "      <td>10.234624</td>\n",
       "      <td>10.324202</td>\n",
       "      <td>12.185028</td>\n",
       "      <td>11.287617</td>\n",
       "      <td>11.257117</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                     1          2          3         4         5  \\\n",
       "timestamp                                                                 \n",
       "2004-01-01 00:30:00  9.732284  11.746091  11.822122  6.182085  8.828934   \n",
       "2004-01-01 01:30:00  9.708081  11.722481  11.798518  6.124683  8.794219   \n",
       "\n",
       "zone_id                      6          7         8          9         10  \\\n",
       "timestamp                                                                   \n",
       "2004-01-01 00:30:00  11.798766  11.822122  8.046870  11.228478  10.057881   \n",
       "2004-01-01 01:30:00  11.774589  11.798518  7.991592  11.117925  10.003333   \n",
       "\n",
       "zone_id              ...         15         16         17         18  \\\n",
       "timestamp            ...                                               \n",
       "2004-01-01 00:30:00  ...  11.096955  10.266463  10.330225  12.210791   \n",
       "2004-01-01 01:30:00  ...  11.075970  10.234624  10.324202  12.185028   \n",
       "\n",
       "zone_id                     19         20  year  month  day  hour  \n",
       "timestamp                                                          \n",
       "2004-01-01 00:30:00  11.318102  11.287655  2004      1    1     0  \n",
       "2004-01-01 01:30:00  11.287617  11.257117  2004      1    1     1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log transformation on load values (no-scaling)\n",
    "load_wide_log = load_wide\n",
    "load_wide_log[list(range(1,21,1))] = load_wide_log[list(range(1,21,1))].apply(np.log)\n",
    "load_wide_log[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3b289-c02e-448f-8510-fc5b744c8355",
   "metadata": {},
   "source": [
    "### Defining Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a73159-056d-4ef7-b268-d4a5d660cd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01 00:30:00</th>\n",
       "      <td>42.338937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 01:30:00</th>\n",
       "      <td>41.239284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 02:30:00</th>\n",
       "      <td>39.591442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp_weighted\n",
       "timestamp                         \n",
       "2004-01-01 00:30:00      42.338937\n",
       "2004-01-01 01:30:00      41.239284\n",
       "2004-01-01 02:30:00      39.591442"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the temperature data\n",
    "temperature = pd.read_csv(r\"C:\\Users\\singh\\Desktop\\TUD (All Semesters)\\Courses - Semester 6 (TU Dresden)\\Thesis Work\\Exploratory Code\\weighted_temperature.csv\")\n",
    "feature_matrix = temperature[[\"timestamp\",\"temp_weighted\"]]\n",
    "feature_matrix.set_index(\"timestamp\", inplace=True)\n",
    "feature_matrix.index = pd.to_datetime(feature_matrix.index)\n",
    "feature_matrix[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9474f00-3be1-46cb-90fa-b4e7e3f62409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_weighted</th>\n",
       "      <th>HDK</th>\n",
       "      <th>CDK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01 00:30:00</th>\n",
       "      <td>42.338937</td>\n",
       "      <td>12.661063</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 01:30:00</th>\n",
       "      <td>41.239284</td>\n",
       "      <td>13.760716</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 02:30:00</th>\n",
       "      <td>39.591442</td>\n",
       "      <td>15.408558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp_weighted        HDK  CDK\n",
       "timestamp                                         \n",
       "2004-01-01 00:30:00      42.338937  12.661063  0.0\n",
       "2004-01-01 01:30:00      41.239284  13.760716  0.0\n",
       "2004-01-01 02:30:00      39.591442  15.408558  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding temperature knots for PLR\n",
    "\n",
    "T_H = 55  # Heating Threshold\n",
    "T_C = 65  # Cooling Threshold\n",
    "\n",
    "# Temporarily changing alias of df\n",
    "mul_df = feature_matrix.copy()\n",
    "\n",
    "# Construct the Heating Demand Knot: HDK = max(0, T_H - Temp)\n",
    "## This captures load increase when temp is below T_H.\n",
    "mul_df[\"HDK\"] = np.where(\n",
    "    mul_df[\"temp_weighted\"] < T_H,  \n",
    "    T_H - mul_df[\"temp_weighted\"],  # Value if True: The positive difference\n",
    "    0                               # Value if False: Zero\n",
    ")\n",
    "\n",
    "# Construct the Cooling Demand Knot; CDK = max(0, Temp - T_C)\n",
    "## This captures load increase when temp is above T_C.\n",
    "mul_df[\"CDK\"] = np.where(\n",
    "    mul_df[\"temp_weighted\"] > T_C,  \n",
    "    mul_df[\"temp_weighted\"] - T_C,  # Value if True: The positive difference\n",
    "    0                               # Value if False: Zero\n",
    ")\n",
    "\n",
    "# Reverting back to original alias\n",
    "feature_matrix = mul_df.copy()\n",
    "feature_matrix[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f524f43-8d22-446f-96b1-c3efc9a86d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_weighted</th>\n",
       "      <th>HDK</th>\n",
       "      <th>CDK</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-06-30 01:30:00</th>\n",
       "      <td>71.080370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.080370</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30 02:30:00</th>\n",
       "      <td>70.803812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.803812</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30 03:30:00</th>\n",
       "      <td>70.248102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.248102</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30 04:30:00</th>\n",
       "      <td>70.065118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.065118</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30 05:30:00</th>\n",
       "      <td>69.793713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.793713</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp_weighted  HDK       CDK  year  month  day  hour\n",
       "timestamp                                                                \n",
       "2008-06-30 01:30:00      71.080370  0.0  6.080370  2008      6   30     1\n",
       "2008-06-30 02:30:00      70.803812  0.0  5.803812  2008      6   30     2\n",
       "2008-06-30 03:30:00      70.248102  0.0  5.248102  2008      6   30     3\n",
       "2008-06-30 04:30:00      70.065118  0.0  5.065118  2008      6   30     4\n",
       "2008-06-30 05:30:00      69.793713  0.0  4.793713  2008      6   30     5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segregating temporal information\n",
    "feature_matrix['year'] = feature_matrix.index.year\n",
    "feature_matrix['month'] = feature_matrix.index.month\n",
    "feature_matrix['day'] = feature_matrix.index.day\n",
    "feature_matrix['hour'] = feature_matrix.index.hour\n",
    "feature_matrix.sort_index(inplace=True)\n",
    "feature_matrix.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b034c1-7515-426d-997c-227ffaa0c19d",
   "metadata": {},
   "source": [
    "### Filling Missing Values: Forecasting & Backcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2a972-f370-4a21-8581-c99c43561033",
   "metadata": {},
   "source": [
    "#### Period 1: 6 Mar 2005 - 12 Mar 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f0c5a1-da3a-4426-a702-ec6d05cde2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2005-03-06 00:30:00\") & (feature_matrix.index > \"2005-02-26 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2005-03-06 00:30:00\") & (load_wide_log.index > \"2005-02-26 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2005-03-21 00:30:00\") & (feature_matrix.index > \"2005-03-12 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2005-03-21 00:30:00\") & (load_wide_log.index > \"2005-03-12 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f935f49-0867-4315-ba29-5299e079d53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c248c974-6c4e-4d7b-a3de-6ba0d3d90338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413ae379-a69b-4ff3-93ec-88ddecde2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_1_X = feature_matrix.loc[(feature_matrix.index >= \"2005-03-06 00:30:00\") & (feature_matrix.index <= \"2005-03-12 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_1_X = period_1_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_1 = period_1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d41f47b-b8e7-483f-8e80-ff4f10cd7409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_1.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_1)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_1.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_1)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9244e1ae-e448-4e14-985d-bebb28976e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-03-06 00:30:00</th>\n",
       "      <td>20802.333067</td>\n",
       "      <td>181539.662243</td>\n",
       "      <td>195881.735649</td>\n",
       "      <td>515.862557</td>\n",
       "      <td>8508.352480</td>\n",
       "      <td>190074.436355</td>\n",
       "      <td>195881.735649</td>\n",
       "      <td>3992.491970</td>\n",
       "      <td>72807.831556</td>\n",
       "      <td>28069.218974</td>\n",
       "      <td>110882.269044</td>\n",
       "      <td>137132.679286</td>\n",
       "      <td>22146.998363</td>\n",
       "      <td>27000.243850</td>\n",
       "      <td>71925.496205</td>\n",
       "      <td>37078.741315</td>\n",
       "      <td>37044.874940</td>\n",
       "      <td>253307.703203</td>\n",
       "      <td>94383.967478</td>\n",
       "      <td>95476.234489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 01:30:00</th>\n",
       "      <td>19973.215360</td>\n",
       "      <td>174698.825433</td>\n",
       "      <td>188500.429198</td>\n",
       "      <td>450.692592</td>\n",
       "      <td>8071.055353</td>\n",
       "      <td>182793.283295</td>\n",
       "      <td>188500.429198</td>\n",
       "      <td>3828.383179</td>\n",
       "      <td>76400.867021</td>\n",
       "      <td>26581.378142</td>\n",
       "      <td>105631.237415</td>\n",
       "      <td>129653.470417</td>\n",
       "      <td>21098.121718</td>\n",
       "      <td>25542.480837</td>\n",
       "      <td>69184.621704</td>\n",
       "      <td>35599.913346</td>\n",
       "      <td>35449.879414</td>\n",
       "      <td>242435.857767</td>\n",
       "      <td>89913.702226</td>\n",
       "      <td>91438.413253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 02:30:00</th>\n",
       "      <td>20286.386948</td>\n",
       "      <td>174443.284904</td>\n",
       "      <td>188224.679160</td>\n",
       "      <td>429.171659</td>\n",
       "      <td>8149.661463</td>\n",
       "      <td>182621.018169</td>\n",
       "      <td>188224.679160</td>\n",
       "      <td>3828.654856</td>\n",
       "      <td>74868.098771</td>\n",
       "      <td>26371.963173</td>\n",
       "      <td>105273.291919</td>\n",
       "      <td>128438.104849</td>\n",
       "      <td>20924.686692</td>\n",
       "      <td>25351.922036</td>\n",
       "      <td>69076.860440</td>\n",
       "      <td>35732.069786</td>\n",
       "      <td>35471.918340</td>\n",
       "      <td>243295.774857</td>\n",
       "      <td>90142.023854</td>\n",
       "      <td>91119.385068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 03:30:00</th>\n",
       "      <td>20662.735856</td>\n",
       "      <td>176178.134673</td>\n",
       "      <td>190096.551622</td>\n",
       "      <td>421.756983</td>\n",
       "      <td>8451.334979</td>\n",
       "      <td>184659.291178</td>\n",
       "      <td>190096.551622</td>\n",
       "      <td>3921.771939</td>\n",
       "      <td>73387.609394</td>\n",
       "      <td>26399.287914</td>\n",
       "      <td>106591.447579</td>\n",
       "      <td>130295.520387</td>\n",
       "      <td>21038.387735</td>\n",
       "      <td>25076.383225</td>\n",
       "      <td>68818.040702</td>\n",
       "      <td>36030.883806</td>\n",
       "      <td>35439.920730</td>\n",
       "      <td>245372.977014</td>\n",
       "      <td>90270.183810</td>\n",
       "      <td>91805.928109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 04:30:00</th>\n",
       "      <td>22609.260386</td>\n",
       "      <td>186350.156991</td>\n",
       "      <td>201072.167632</td>\n",
       "      <td>469.263193</td>\n",
       "      <td>9340.754610</td>\n",
       "      <td>195716.078376</td>\n",
       "      <td>201072.167632</td>\n",
       "      <td>4191.027546</td>\n",
       "      <td>65996.904569</td>\n",
       "      <td>28126.611810</td>\n",
       "      <td>114029.327321</td>\n",
       "      <td>139284.426934</td>\n",
       "      <td>22304.391334</td>\n",
       "      <td>26648.556982</td>\n",
       "      <td>72503.750295</td>\n",
       "      <td>38479.775617</td>\n",
       "      <td>37731.246950</td>\n",
       "      <td>263217.569879</td>\n",
       "      <td>97061.920752</td>\n",
       "      <td>97245.223276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2005-03-06 00:30:00  20802.333067  181539.662243  195881.735649   515.862557   \n",
       "2005-03-06 01:30:00  19973.215360  174698.825433  188500.429198   450.692592   \n",
       "2005-03-06 02:30:00  20286.386948  174443.284904  188224.679160   429.171659   \n",
       "2005-03-06 03:30:00  20662.735856  176178.134673  190096.551622   421.756983   \n",
       "2005-03-06 04:30:00  22609.260386  186350.156991  201072.167632   469.263193   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-03-06 00:30:00  8508.352480  190074.436355  195881.735649  3992.491970   \n",
       "2005-03-06 01:30:00  8071.055353  182793.283295  188500.429198  3828.383179   \n",
       "2005-03-06 02:30:00  8149.661463  182621.018169  188224.679160  3828.654856   \n",
       "2005-03-06 03:30:00  8451.334979  184659.291178  190096.551622  3921.771939   \n",
       "2005-03-06 04:30:00  9340.754610  195716.078376  201072.167632  4191.027546   \n",
       "\n",
       "                      Zone_9_pred  Zone_10_pred   Zone_11_pred   Zone_12_pred  \\\n",
       "timestamp                                                                       \n",
       "2005-03-06 00:30:00  72807.831556  28069.218974  110882.269044  137132.679286   \n",
       "2005-03-06 01:30:00  76400.867021  26581.378142  105631.237415  129653.470417   \n",
       "2005-03-06 02:30:00  74868.098771  26371.963173  105273.291919  128438.104849   \n",
       "2005-03-06 03:30:00  73387.609394  26399.287914  106591.447579  130295.520387   \n",
       "2005-03-06 04:30:00  65996.904569  28126.611810  114029.327321  139284.426934   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-03-06 00:30:00  22146.998363  27000.243850  71925.496205  37078.741315   \n",
       "2005-03-06 01:30:00  21098.121718  25542.480837  69184.621704  35599.913346   \n",
       "2005-03-06 02:30:00  20924.686692  25351.922036  69076.860440  35732.069786   \n",
       "2005-03-06 03:30:00  21038.387735  25076.383225  68818.040702  36030.883806   \n",
       "2005-03-06 04:30:00  22304.391334  26648.556982  72503.750295  38479.775617   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred  Zone_19_pred  Zone_20_pred  \n",
       "timestamp                                                                     \n",
       "2005-03-06 00:30:00  37044.874940  253307.703203  94383.967478  95476.234489  \n",
       "2005-03-06 01:30:00  35449.879414  242435.857767  89913.702226  91438.413253  \n",
       "2005-03-06 02:30:00  35471.918340  243295.774857  90142.023854  91119.385068  \n",
       "2005-03-06 03:30:00  35439.920730  245372.977014  90270.183810  91805.928109  \n",
       "2005-03-06 04:30:00  37731.246950  263217.569879  97061.920752  97245.223276  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p1_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p1_mean_unlogged = np.exp(predictions_p1_mean)\n",
    "predictions_p1_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2377f179-2ea4-4ce5-8c28-5c55bb1b6f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-03-06 00:30:00</th>\n",
       "      <td>18954.0</td>\n",
       "      <td>162388.0</td>\n",
       "      <td>175217.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>8530.0</td>\n",
       "      <td>170918.0</td>\n",
       "      <td>175217.0</td>\n",
       "      <td>4054.0</td>\n",
       "      <td>80850.0</td>\n",
       "      <td>25031.0</td>\n",
       "      <td>108347.0</td>\n",
       "      <td>142581.0</td>\n",
       "      <td>22016.0</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>70602.0</td>\n",
       "      <td>36004.0</td>\n",
       "      <td>34078.0</td>\n",
       "      <td>245140.0</td>\n",
       "      <td>91067.0</td>\n",
       "      <td>85633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 01:30:00</th>\n",
       "      <td>19614.0</td>\n",
       "      <td>161693.0</td>\n",
       "      <td>174468.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>8437.0</td>\n",
       "      <td>170131.0</td>\n",
       "      <td>174468.0</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>80241.0</td>\n",
       "      <td>24794.0</td>\n",
       "      <td>106572.0</td>\n",
       "      <td>138708.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>25967.0</td>\n",
       "      <td>70621.0</td>\n",
       "      <td>36449.0</td>\n",
       "      <td>33875.0</td>\n",
       "      <td>247743.0</td>\n",
       "      <td>91186.0</td>\n",
       "      <td>85038.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2005-03-06 00:30:00  18954.0  162388.0  175217.0  531.0  8530.0  170918.0   \n",
       "2005-03-06 01:30:00  19614.0  161693.0  174468.0  502.0  8437.0  170131.0   \n",
       "\n",
       "zone_id                     7       8        9       10        11        12  \\\n",
       "timestamp                                                                     \n",
       "2005-03-06 00:30:00  175217.0  4054.0  80850.0  25031.0  108347.0  142581.0   \n",
       "2005-03-06 01:30:00  174468.0  4009.0  80241.0  24794.0  106572.0  138708.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2005-03-06 00:30:00  22016.0  25947.0  70602.0  36004.0  34078.0  245140.0   \n",
       "2005-03-06 01:30:00  22100.0  25967.0  70621.0  36449.0  33875.0  247743.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2005-03-06 00:30:00  91067.0  85633.0  \n",
       "2005-03-06 01:30:00  91186.0  85038.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p1_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_1_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p1_unlogged.index = period_1_X.index\n",
    "last_cycle_naive_p1_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616aed76-9a34-41c5-b707-340144a97ebd",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b4a50-d429-4bc5-a2d4-77778008e62a",
   "metadata": {},
   "source": [
    "#### Period 2: 20 Jun 2005 - 26 Jun 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff9cac55-dac4-40f4-9600-21af64644937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2005-06-20 00:30:00\") & (feature_matrix.index > \"2005-06-11 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2005-06-20 00:30:00\") & (load_wide_log.index > \"2005-06-11 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2005-07-05 00:30:00\") & (feature_matrix.index > \"2005-06-26 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2005-07-05 00:30:00\") & (load_wide_log.index > \"2005-06-26 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "726e1118-e2fa-45a3-90f4-a6d9e9283873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2123f871-4019-46c3-a005-31ac54000b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b9ff72-c6d8-4578-9c76-71c59e697d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_2_X = feature_matrix.loc[(feature_matrix.index >= \"2005-06-20 00:30:00\") & (feature_matrix.index <= \"2005-06-26 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_2_X = period_2_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_2 = period_2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eee939b-c38c-4e40-a87d-244a37f99e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_2.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_2)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_2.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_2)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "994a8eb3-4e42-443d-8274-744808305035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-06-20 00:30:00</th>\n",
       "      <td>13504.556262</td>\n",
       "      <td>145093.576382</td>\n",
       "      <td>156556.262647</td>\n",
       "      <td>364.718400</td>\n",
       "      <td>6399.274188</td>\n",
       "      <td>151544.063843</td>\n",
       "      <td>156556.262647</td>\n",
       "      <td>2820.022518</td>\n",
       "      <td>125845.887423</td>\n",
       "      <td>19634.518332</td>\n",
       "      <td>81572.032755</td>\n",
       "      <td>96813.494347</td>\n",
       "      <td>15378.668400</td>\n",
       "      <td>15011.125419</td>\n",
       "      <td>49762.189115</td>\n",
       "      <td>21303.391412</td>\n",
       "      <td>25921.193033</td>\n",
       "      <td>166304.302301</td>\n",
       "      <td>57560.478824</td>\n",
       "      <td>71558.947693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-20 01:30:00</th>\n",
       "      <td>12166.159439</td>\n",
       "      <td>136763.682890</td>\n",
       "      <td>147568.241105</td>\n",
       "      <td>331.091010</td>\n",
       "      <td>5633.966571</td>\n",
       "      <td>142406.174870</td>\n",
       "      <td>147568.241105</td>\n",
       "      <td>2554.699683</td>\n",
       "      <td>120142.150116</td>\n",
       "      <td>18668.054841</td>\n",
       "      <td>75407.283944</td>\n",
       "      <td>87942.671345</td>\n",
       "      <td>13804.258880</td>\n",
       "      <td>13454.856233</td>\n",
       "      <td>45829.461950</td>\n",
       "      <td>19253.107612</td>\n",
       "      <td>24178.050249</td>\n",
       "      <td>149243.626799</td>\n",
       "      <td>51590.230084</td>\n",
       "      <td>65921.862974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-20 02:30:00</th>\n",
       "      <td>11243.720139</td>\n",
       "      <td>130792.901940</td>\n",
       "      <td>141125.713069</td>\n",
       "      <td>312.356438</td>\n",
       "      <td>5118.225889</td>\n",
       "      <td>135882.762859</td>\n",
       "      <td>141125.713069</td>\n",
       "      <td>2387.431874</td>\n",
       "      <td>115225.413850</td>\n",
       "      <td>18002.037758</td>\n",
       "      <td>71080.668898</td>\n",
       "      <td>81617.380364</td>\n",
       "      <td>12775.167397</td>\n",
       "      <td>12315.339761</td>\n",
       "      <td>42855.204878</td>\n",
       "      <td>17802.707556</td>\n",
       "      <td>22890.700755</td>\n",
       "      <td>137299.678043</td>\n",
       "      <td>47368.968530</td>\n",
       "      <td>62234.546530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-20 03:30:00</th>\n",
       "      <td>10779.228656</td>\n",
       "      <td>127827.823412</td>\n",
       "      <td>137926.356024</td>\n",
       "      <td>309.396679</td>\n",
       "      <td>4861.607586</td>\n",
       "      <td>132643.605086</td>\n",
       "      <td>137926.356024</td>\n",
       "      <td>2323.762097</td>\n",
       "      <td>112096.880334</td>\n",
       "      <td>17729.627280</td>\n",
       "      <td>68981.339960</td>\n",
       "      <td>78316.168897</td>\n",
       "      <td>12383.135081</td>\n",
       "      <td>11687.981522</td>\n",
       "      <td>41214.766341</td>\n",
       "      <td>17068.020933</td>\n",
       "      <td>22196.412772</td>\n",
       "      <td>131249.214507</td>\n",
       "      <td>45223.644328</td>\n",
       "      <td>60865.643369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-20 04:30:00</th>\n",
       "      <td>10759.528174</td>\n",
       "      <td>127973.356905</td>\n",
       "      <td>138083.369424</td>\n",
       "      <td>321.644278</td>\n",
       "      <td>4847.569331</td>\n",
       "      <td>132781.047477</td>\n",
       "      <td>138083.369424</td>\n",
       "      <td>2359.858843</td>\n",
       "      <td>111749.641240</td>\n",
       "      <td>17849.845731</td>\n",
       "      <td>69123.228430</td>\n",
       "      <td>78035.514218</td>\n",
       "      <td>12633.899241</td>\n",
       "      <td>11567.128792</td>\n",
       "      <td>41001.476444</td>\n",
       "      <td>17048.046324</td>\n",
       "      <td>22108.162303</td>\n",
       "      <td>131016.867690</td>\n",
       "      <td>45129.283567</td>\n",
       "      <td>61817.719413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2005-06-20 00:30:00  13504.556262  145093.576382  156556.262647   364.718400   \n",
       "2005-06-20 01:30:00  12166.159439  136763.682890  147568.241105   331.091010   \n",
       "2005-06-20 02:30:00  11243.720139  130792.901940  141125.713069   312.356438   \n",
       "2005-06-20 03:30:00  10779.228656  127827.823412  137926.356024   309.396679   \n",
       "2005-06-20 04:30:00  10759.528174  127973.356905  138083.369424   321.644278   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-06-20 00:30:00  6399.274188  151544.063843  156556.262647  2820.022518   \n",
       "2005-06-20 01:30:00  5633.966571  142406.174870  147568.241105  2554.699683   \n",
       "2005-06-20 02:30:00  5118.225889  135882.762859  141125.713069  2387.431874   \n",
       "2005-06-20 03:30:00  4861.607586  132643.605086  137926.356024  2323.762097   \n",
       "2005-06-20 04:30:00  4847.569331  132781.047477  138083.369424  2359.858843   \n",
       "\n",
       "                       Zone_9_pred  Zone_10_pred  Zone_11_pred  Zone_12_pred  \\\n",
       "timestamp                                                                      \n",
       "2005-06-20 00:30:00  125845.887423  19634.518332  81572.032755  96813.494347   \n",
       "2005-06-20 01:30:00  120142.150116  18668.054841  75407.283944  87942.671345   \n",
       "2005-06-20 02:30:00  115225.413850  18002.037758  71080.668898  81617.380364   \n",
       "2005-06-20 03:30:00  112096.880334  17729.627280  68981.339960  78316.168897   \n",
       "2005-06-20 04:30:00  111749.641240  17849.845731  69123.228430  78035.514218   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-06-20 00:30:00  15378.668400  15011.125419  49762.189115  21303.391412   \n",
       "2005-06-20 01:30:00  13804.258880  13454.856233  45829.461950  19253.107612   \n",
       "2005-06-20 02:30:00  12775.167397  12315.339761  42855.204878  17802.707556   \n",
       "2005-06-20 03:30:00  12383.135081  11687.981522  41214.766341  17068.020933   \n",
       "2005-06-20 04:30:00  12633.899241  11567.128792  41001.476444  17048.046324   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred  Zone_19_pred  Zone_20_pred  \n",
       "timestamp                                                                     \n",
       "2005-06-20 00:30:00  25921.193033  166304.302301  57560.478824  71558.947693  \n",
       "2005-06-20 01:30:00  24178.050249  149243.626799  51590.230084  65921.862974  \n",
       "2005-06-20 02:30:00  22890.700755  137299.678043  47368.968530  62234.546530  \n",
       "2005-06-20 03:30:00  22196.412772  131249.214507  45223.644328  60865.643369  \n",
       "2005-06-20 04:30:00  22108.162303  131016.867690  45129.283567  61817.719413  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p2_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p2_mean_unlogged = np.exp(predictions_p2_mean)\n",
    "predictions_p2_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "036d82d7-3dc5-41bd-87f0-fa0ea2f31d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-06-20 00:30:00</th>\n",
       "      <td>15416.0</td>\n",
       "      <td>149278.0</td>\n",
       "      <td>161072.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>6698.0</td>\n",
       "      <td>155977.0</td>\n",
       "      <td>161072.0</td>\n",
       "      <td>2859.0</td>\n",
       "      <td>82992.0</td>\n",
       "      <td>21079.0</td>\n",
       "      <td>92005.0</td>\n",
       "      <td>117462.0</td>\n",
       "      <td>15390.0</td>\n",
       "      <td>20707.0</td>\n",
       "      <td>56611.0</td>\n",
       "      <td>26251.0</td>\n",
       "      <td>31975.0</td>\n",
       "      <td>185626.0</td>\n",
       "      <td>71916.0</td>\n",
       "      <td>71910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-20 01:30:00</th>\n",
       "      <td>14390.0</td>\n",
       "      <td>143795.0</td>\n",
       "      <td>155155.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>5938.0</td>\n",
       "      <td>149733.0</td>\n",
       "      <td>155155.0</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>82551.0</td>\n",
       "      <td>20259.0</td>\n",
       "      <td>84773.0</td>\n",
       "      <td>106672.0</td>\n",
       "      <td>14315.0</td>\n",
       "      <td>18792.0</td>\n",
       "      <td>52290.0</td>\n",
       "      <td>24402.0</td>\n",
       "      <td>30406.0</td>\n",
       "      <td>170506.0</td>\n",
       "      <td>65670.0</td>\n",
       "      <td>67696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2005-06-20 00:30:00  15416.0  149278.0  161072.0  337.0  6698.0  155977.0   \n",
       "2005-06-20 01:30:00  14390.0  143795.0  155155.0  322.0  5938.0  149733.0   \n",
       "\n",
       "zone_id                     7       8        9       10       11        12  \\\n",
       "timestamp                                                                    \n",
       "2005-06-20 00:30:00  161072.0  2859.0  82992.0  21079.0  92005.0  117462.0   \n",
       "2005-06-20 01:30:00  155155.0  2622.0  82551.0  20259.0  84773.0  106672.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2005-06-20 00:30:00  15390.0  20707.0  56611.0  26251.0  31975.0  185626.0   \n",
       "2005-06-20 01:30:00  14315.0  18792.0  52290.0  24402.0  30406.0  170506.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2005-06-20 00:30:00  71916.0  71910.0  \n",
       "2005-06-20 01:30:00  65670.0  67696.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p2_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_2_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p2_unlogged.index = period_2_X.index\n",
    "last_cycle_naive_p2_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da46a7-2c6b-40b4-bd81-af2ba163a484",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6259820-f53a-42ab-867d-0e2e7c6cc1c2",
   "metadata": {},
   "source": [
    "#### Period 3: 10 Sep 2005 - 16 Sep 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a2f45cc-ae67-4724-bdb9-c7c238b3fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2005-09-10 00:30:00\") & (feature_matrix.index > \"2005-09-02 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2005-09-10 00:30:00\") & (load_wide_log.index > \"2005-09-02 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2005-09-23 00:30:00\") & (feature_matrix.index > \"2005-09-16 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2005-09-23 00:30:00\") & (load_wide_log.index > \"2005-09-16 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d356fcf-8dc4-4df8-a1e9-56058a7ed54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8b80563-b92f-496f-a41c-ddba2c2ca1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc09c0f-b3e1-4fac-98b4-e03cfdd1e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_3_X = feature_matrix.loc[(feature_matrix.index >= \"2005-09-10 00:30:00\") & (feature_matrix.index <= \"2005-09-16 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_3_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_3_X = period_3_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_3 = period_3_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bbe0cb0-db75-4ad7-a965-9f8a06e97be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_3.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_3)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_3.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_3)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af25ca1c-4f7a-46a9-9881-ecc36699c103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-09-10 00:30:00</th>\n",
       "      <td>13425.883573</td>\n",
       "      <td>122054.244571</td>\n",
       "      <td>131696.672907</td>\n",
       "      <td>367.683934</td>\n",
       "      <td>5384.740671</td>\n",
       "      <td>127563.990687</td>\n",
       "      <td>131696.672907</td>\n",
       "      <td>2336.080305</td>\n",
       "      <td>84391.913014</td>\n",
       "      <td>21493.045380</td>\n",
       "      <td>79240.755312</td>\n",
       "      <td>103454.379890</td>\n",
       "      <td>13835.562835</td>\n",
       "      <td>16743.086052</td>\n",
       "      <td>55722.818008</td>\n",
       "      <td>23464.707087</td>\n",
       "      <td>25988.445722</td>\n",
       "      <td>152444.845747</td>\n",
       "      <td>60834.793698</td>\n",
       "      <td>59056.746830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-10 01:30:00</th>\n",
       "      <td>12097.596747</td>\n",
       "      <td>115132.261389</td>\n",
       "      <td>124227.886388</td>\n",
       "      <td>333.820135</td>\n",
       "      <td>4717.108618</td>\n",
       "      <td>119965.287451</td>\n",
       "      <td>124227.886388</td>\n",
       "      <td>2130.772417</td>\n",
       "      <td>84481.820830</td>\n",
       "      <td>19994.374166</td>\n",
       "      <td>72378.371390</td>\n",
       "      <td>92622.708310</td>\n",
       "      <td>12595.157847</td>\n",
       "      <td>14807.884063</td>\n",
       "      <td>51438.841048</td>\n",
       "      <td>21083.712750</td>\n",
       "      <td>24034.212123</td>\n",
       "      <td>137225.546876</td>\n",
       "      <td>54466.873981</td>\n",
       "      <td>54729.625066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-10 02:30:00</th>\n",
       "      <td>11341.586226</td>\n",
       "      <td>111282.360240</td>\n",
       "      <td>120073.878546</td>\n",
       "      <td>317.887531</td>\n",
       "      <td>4373.430353</td>\n",
       "      <td>115754.691852</td>\n",
       "      <td>120073.878546</td>\n",
       "      <td>2038.752907</td>\n",
       "      <td>83948.875889</td>\n",
       "      <td>19082.333836</td>\n",
       "      <td>68398.931059</td>\n",
       "      <td>86201.658655</td>\n",
       "      <td>11945.044228</td>\n",
       "      <td>13636.305811</td>\n",
       "      <td>48808.259913</td>\n",
       "      <td>19680.134495</td>\n",
       "      <td>22867.779837</td>\n",
       "      <td>128667.124540</td>\n",
       "      <td>50800.745741</td>\n",
       "      <td>52612.882715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-10 03:30:00</th>\n",
       "      <td>11125.530327</td>\n",
       "      <td>110700.758997</td>\n",
       "      <td>119446.364748</td>\n",
       "      <td>320.150629</td>\n",
       "      <td>4322.210727</td>\n",
       "      <td>115115.257107</td>\n",
       "      <td>119446.364748</td>\n",
       "      <td>2053.102612</td>\n",
       "      <td>83148.879114</td>\n",
       "      <td>18827.025341</td>\n",
       "      <td>67378.024184</td>\n",
       "      <td>84095.068609</td>\n",
       "      <td>11912.799052</td>\n",
       "      <td>13205.596076</td>\n",
       "      <td>47939.245034</td>\n",
       "      <td>19252.235200</td>\n",
       "      <td>22504.593792</td>\n",
       "      <td>126637.545707</td>\n",
       "      <td>49762.133316</td>\n",
       "      <td>52762.792599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-10 04:30:00</th>\n",
       "      <td>11386.478239</td>\n",
       "      <td>113187.670563</td>\n",
       "      <td>122129.770098</td>\n",
       "      <td>339.397518</td>\n",
       "      <td>4525.803454</td>\n",
       "      <td>117810.377822</td>\n",
       "      <td>122129.770098</td>\n",
       "      <td>2159.932774</td>\n",
       "      <td>82260.332876</td>\n",
       "      <td>19215.531463</td>\n",
       "      <td>69075.243495</td>\n",
       "      <td>85843.420987</td>\n",
       "      <td>12472.672747</td>\n",
       "      <td>13441.815270</td>\n",
       "      <td>48733.108391</td>\n",
       "      <td>19702.702721</td>\n",
       "      <td>22886.642892</td>\n",
       "      <td>130546.711354</td>\n",
       "      <td>51094.247811</td>\n",
       "      <td>55026.162764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2005-09-10 00:30:00  13425.883573  122054.244571  131696.672907   367.683934   \n",
       "2005-09-10 01:30:00  12097.596747  115132.261389  124227.886388   333.820135   \n",
       "2005-09-10 02:30:00  11341.586226  111282.360240  120073.878546   317.887531   \n",
       "2005-09-10 03:30:00  11125.530327  110700.758997  119446.364748   320.150629   \n",
       "2005-09-10 04:30:00  11386.478239  113187.670563  122129.770098   339.397518   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-09-10 00:30:00  5384.740671  127563.990687  131696.672907  2336.080305   \n",
       "2005-09-10 01:30:00  4717.108618  119965.287451  124227.886388  2130.772417   \n",
       "2005-09-10 02:30:00  4373.430353  115754.691852  120073.878546  2038.752907   \n",
       "2005-09-10 03:30:00  4322.210727  115115.257107  119446.364748  2053.102612   \n",
       "2005-09-10 04:30:00  4525.803454  117810.377822  122129.770098  2159.932774   \n",
       "\n",
       "                      Zone_9_pred  Zone_10_pred  Zone_11_pred   Zone_12_pred  \\\n",
       "timestamp                                                                      \n",
       "2005-09-10 00:30:00  84391.913014  21493.045380  79240.755312  103454.379890   \n",
       "2005-09-10 01:30:00  84481.820830  19994.374166  72378.371390   92622.708310   \n",
       "2005-09-10 02:30:00  83948.875889  19082.333836  68398.931059   86201.658655   \n",
       "2005-09-10 03:30:00  83148.879114  18827.025341  67378.024184   84095.068609   \n",
       "2005-09-10 04:30:00  82260.332876  19215.531463  69075.243495   85843.420987   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-09-10 00:30:00  13835.562835  16743.086052  55722.818008  23464.707087   \n",
       "2005-09-10 01:30:00  12595.157847  14807.884063  51438.841048  21083.712750   \n",
       "2005-09-10 02:30:00  11945.044228  13636.305811  48808.259913  19680.134495   \n",
       "2005-09-10 03:30:00  11912.799052  13205.596076  47939.245034  19252.235200   \n",
       "2005-09-10 04:30:00  12472.672747  13441.815270  48733.108391  19702.702721   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred  Zone_19_pred  Zone_20_pred  \n",
       "timestamp                                                                     \n",
       "2005-09-10 00:30:00  25988.445722  152444.845747  60834.793698  59056.746830  \n",
       "2005-09-10 01:30:00  24034.212123  137225.546876  54466.873981  54729.625066  \n",
       "2005-09-10 02:30:00  22867.779837  128667.124540  50800.745741  52612.882715  \n",
       "2005-09-10 03:30:00  22504.593792  126637.545707  49762.133316  52762.792599  \n",
       "2005-09-10 04:30:00  22886.642892  130546.711354  51094.247811  55026.162764  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p3_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p3_mean_unlogged = np.exp(predictions_p3_mean)\n",
    "predictions_p3_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f16ac85-71cb-4989-a31d-b0088dfb9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-09-10 00:30:00</th>\n",
       "      <td>14051.0</td>\n",
       "      <td>142723.0</td>\n",
       "      <td>153999.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>6045.0</td>\n",
       "      <td>148768.0</td>\n",
       "      <td>153999.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>95193.0</td>\n",
       "      <td>27228.0</td>\n",
       "      <td>96888.0</td>\n",
       "      <td>121831.0</td>\n",
       "      <td>14637.0</td>\n",
       "      <td>16886.0</td>\n",
       "      <td>57439.0</td>\n",
       "      <td>27612.0</td>\n",
       "      <td>26608.0</td>\n",
       "      <td>172283.0</td>\n",
       "      <td>62838.0</td>\n",
       "      <td>65611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-10 01:30:00</th>\n",
       "      <td>12366.0</td>\n",
       "      <td>133690.0</td>\n",
       "      <td>144251.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>5152.0</td>\n",
       "      <td>138841.0</td>\n",
       "      <td>144251.0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>94983.0</td>\n",
       "      <td>25381.0</td>\n",
       "      <td>86992.0</td>\n",
       "      <td>106760.0</td>\n",
       "      <td>13390.0</td>\n",
       "      <td>14886.0</td>\n",
       "      <td>53102.0</td>\n",
       "      <td>24180.0</td>\n",
       "      <td>24548.0</td>\n",
       "      <td>151473.0</td>\n",
       "      <td>55876.0</td>\n",
       "      <td>60123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2005-09-10 00:30:00  14051.0  142723.0  153999.0  401.0  6045.0  148768.0   \n",
       "2005-09-10 01:30:00  12366.0  133690.0  144251.0  342.0  5152.0  138841.0   \n",
       "\n",
       "zone_id                     7       8        9       10       11        12  \\\n",
       "timestamp                                                                    \n",
       "2005-09-10 00:30:00  153999.0  2550.0  95193.0  27228.0  96888.0  121831.0   \n",
       "2005-09-10 01:30:00  144251.0  2252.0  94983.0  25381.0  86992.0  106760.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2005-09-10 00:30:00  14637.0  16886.0  57439.0  27612.0  26608.0  172283.0   \n",
       "2005-09-10 01:30:00  13390.0  14886.0  53102.0  24180.0  24548.0  151473.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2005-09-10 00:30:00  62838.0  65611.0  \n",
       "2005-09-10 01:30:00  55876.0  60123.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p3_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_3_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p3_unlogged.index = period_3_X.index\n",
    "last_cycle_naive_p3_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194f9f2-eebd-4c74-967f-cb0e0395b97c",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cccccd-6c32-4ae7-8241-ad69722a94bb",
   "metadata": {},
   "source": [
    "#### Period 4: 25 Dec 2005 - 31 Dec 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eef45a12-3c26-4dc5-9bdf-78d3701e6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2005-12-25 00:30:00\") & (feature_matrix.index > \"2005-12-16 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2005-12-25 00:30:00\") & (load_wide_log.index > \"2005-12-16 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2006-01-08 00:30:00\") & (feature_matrix.index > \"2005-12-31 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2006-01-08 00:30:00\") & (load_wide_log.index > \"2005-12-31 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba00f215-e58d-4468-bda2-24bacf46f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a634604d-4ef8-489e-989a-1b921824eddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8844328-ad9e-4394-80e6-263ce47ec7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_4_X = feature_matrix.loc[(feature_matrix.index >= \"2005-12-25 00:30:00\") & (feature_matrix.index <= \"2005-12-31 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_4_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_4_X = period_4_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_4 = period_4_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ad5c60c-e71b-4c3c-a7ca-91cf814fc43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_4.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_4)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_4.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_4)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "215e8907-bd77-4b9c-94eb-0192a67a8b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-12-25 00:30:00</th>\n",
       "      <td>20239.251798</td>\n",
       "      <td>156775.809325</td>\n",
       "      <td>169161.415787</td>\n",
       "      <td>540.197777</td>\n",
       "      <td>8869.077605</td>\n",
       "      <td>165624.292266</td>\n",
       "      <td>169161.415787</td>\n",
       "      <td>3976.485902</td>\n",
       "      <td>74087.670074</td>\n",
       "      <td>23768.841135</td>\n",
       "      <td>103095.729938</td>\n",
       "      <td>141329.893289</td>\n",
       "      <td>22823.746281</td>\n",
       "      <td>28408.316818</td>\n",
       "      <td>72894.234129</td>\n",
       "      <td>36177.679773</td>\n",
       "      <td>35785.845070</td>\n",
       "      <td>246025.511379</td>\n",
       "      <td>95467.692465</td>\n",
       "      <td>87854.138456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-25 01:30:00</th>\n",
       "      <td>19509.693300</td>\n",
       "      <td>151378.578832</td>\n",
       "      <td>163337.788075</td>\n",
       "      <td>509.114419</td>\n",
       "      <td>8390.598859</td>\n",
       "      <td>159766.268875</td>\n",
       "      <td>163337.788075</td>\n",
       "      <td>3795.568385</td>\n",
       "      <td>76093.432463</td>\n",
       "      <td>22732.694874</td>\n",
       "      <td>97804.916983</td>\n",
       "      <td>132436.581440</td>\n",
       "      <td>21768.515890</td>\n",
       "      <td>27111.095548</td>\n",
       "      <td>70603.976150</td>\n",
       "      <td>34745.192728</td>\n",
       "      <td>34613.241468</td>\n",
       "      <td>237535.080155</td>\n",
       "      <td>91883.497129</td>\n",
       "      <td>84526.143658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-25 02:30:00</th>\n",
       "      <td>19509.896884</td>\n",
       "      <td>149876.675409</td>\n",
       "      <td>161717.239493</td>\n",
       "      <td>498.459523</td>\n",
       "      <td>8338.802026</td>\n",
       "      <td>158218.300859</td>\n",
       "      <td>161717.239493</td>\n",
       "      <td>3751.567753</td>\n",
       "      <td>77907.052412</td>\n",
       "      <td>22411.091858</td>\n",
       "      <td>96196.929326</td>\n",
       "      <td>129108.586277</td>\n",
       "      <td>21275.748768</td>\n",
       "      <td>26534.674374</td>\n",
       "      <td>69695.608477</td>\n",
       "      <td>34390.762192</td>\n",
       "      <td>34341.861098</td>\n",
       "      <td>236494.527635</td>\n",
       "      <td>90961.852901</td>\n",
       "      <td>83412.782395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-25 03:30:00</th>\n",
       "      <td>20157.878083</td>\n",
       "      <td>152069.612446</td>\n",
       "      <td>164083.443467</td>\n",
       "      <td>507.323345</td>\n",
       "      <td>8669.180826</td>\n",
       "      <td>160736.211227</td>\n",
       "      <td>164083.443467</td>\n",
       "      <td>3832.634946</td>\n",
       "      <td>78666.171464</td>\n",
       "      <td>22747.410704</td>\n",
       "      <td>97914.912906</td>\n",
       "      <td>130792.818791</td>\n",
       "      <td>21341.884974</td>\n",
       "      <td>26585.597898</td>\n",
       "      <td>70094.682715</td>\n",
       "      <td>34919.812108</td>\n",
       "      <td>34868.593550</td>\n",
       "      <td>241771.724650</td>\n",
       "      <td>92369.750644</td>\n",
       "      <td>84384.315226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-25 04:30:00</th>\n",
       "      <td>21231.816343</td>\n",
       "      <td>157164.060258</td>\n",
       "      <td>169580.392660</td>\n",
       "      <td>532.043698</td>\n",
       "      <td>9278.781684</td>\n",
       "      <td>166420.035364</td>\n",
       "      <td>169580.392660</td>\n",
       "      <td>4006.390134</td>\n",
       "      <td>77770.369611</td>\n",
       "      <td>23575.903354</td>\n",
       "      <td>102072.654415</td>\n",
       "      <td>136183.041986</td>\n",
       "      <td>21867.420325</td>\n",
       "      <td>27031.464543</td>\n",
       "      <td>71400.868333</td>\n",
       "      <td>35942.376942</td>\n",
       "      <td>35906.386612</td>\n",
       "      <td>250868.275810</td>\n",
       "      <td>95241.318860</td>\n",
       "      <td>86948.976345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2005-12-25 00:30:00  20239.251798  156775.809325  169161.415787   540.197777   \n",
       "2005-12-25 01:30:00  19509.693300  151378.578832  163337.788075   509.114419   \n",
       "2005-12-25 02:30:00  19509.896884  149876.675409  161717.239493   498.459523   \n",
       "2005-12-25 03:30:00  20157.878083  152069.612446  164083.443467   507.323345   \n",
       "2005-12-25 04:30:00  21231.816343  157164.060258  169580.392660   532.043698   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-12-25 00:30:00  8869.077605  165624.292266  169161.415787  3976.485902   \n",
       "2005-12-25 01:30:00  8390.598859  159766.268875  163337.788075  3795.568385   \n",
       "2005-12-25 02:30:00  8338.802026  158218.300859  161717.239493  3751.567753   \n",
       "2005-12-25 03:30:00  8669.180826  160736.211227  164083.443467  3832.634946   \n",
       "2005-12-25 04:30:00  9278.781684  166420.035364  169580.392660  4006.390134   \n",
       "\n",
       "                      Zone_9_pred  Zone_10_pred   Zone_11_pred   Zone_12_pred  \\\n",
       "timestamp                                                                       \n",
       "2005-12-25 00:30:00  74087.670074  23768.841135  103095.729938  141329.893289   \n",
       "2005-12-25 01:30:00  76093.432463  22732.694874   97804.916983  132436.581440   \n",
       "2005-12-25 02:30:00  77907.052412  22411.091858   96196.929326  129108.586277   \n",
       "2005-12-25 03:30:00  78666.171464  22747.410704   97914.912906  130792.818791   \n",
       "2005-12-25 04:30:00  77770.369611  23575.903354  102072.654415  136183.041986   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2005-12-25 00:30:00  22823.746281  28408.316818  72894.234129  36177.679773   \n",
       "2005-12-25 01:30:00  21768.515890  27111.095548  70603.976150  34745.192728   \n",
       "2005-12-25 02:30:00  21275.748768  26534.674374  69695.608477  34390.762192   \n",
       "2005-12-25 03:30:00  21341.884974  26585.597898  70094.682715  34919.812108   \n",
       "2005-12-25 04:30:00  21867.420325  27031.464543  71400.868333  35942.376942   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred  Zone_19_pred  Zone_20_pred  \n",
       "timestamp                                                                     \n",
       "2005-12-25 00:30:00  35785.845070  246025.511379  95467.692465  87854.138456  \n",
       "2005-12-25 01:30:00  34613.241468  237535.080155  91883.497129  84526.143658  \n",
       "2005-12-25 02:30:00  34341.861098  236494.527635  90961.852901  83412.782395  \n",
       "2005-12-25 03:30:00  34868.593550  241771.724650  92369.750644  84384.315226  \n",
       "2005-12-25 04:30:00  35906.386612  250868.275810  95241.318860  86948.976345  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p4_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p4_mean_unlogged = np.exp(predictions_p4_mean)\n",
    "predictions_p4_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c9e8a7-7a87-4658-b6b5-9e73cef9eab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-12-25 00:30:00</th>\n",
       "      <td>21429.0</td>\n",
       "      <td>179903.0</td>\n",
       "      <td>194116.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>10044.0</td>\n",
       "      <td>189947.0</td>\n",
       "      <td>194116.0</td>\n",
       "      <td>4456.0</td>\n",
       "      <td>80115.0</td>\n",
       "      <td>24745.0</td>\n",
       "      <td>109326.0</td>\n",
       "      <td>146826.0</td>\n",
       "      <td>23890.0</td>\n",
       "      <td>26423.0</td>\n",
       "      <td>74062.0</td>\n",
       "      <td>37538.0</td>\n",
       "      <td>35435.0</td>\n",
       "      <td>263232.0</td>\n",
       "      <td>96292.0</td>\n",
       "      <td>94372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-25 01:30:00</th>\n",
       "      <td>21124.0</td>\n",
       "      <td>174678.0</td>\n",
       "      <td>188478.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>9628.0</td>\n",
       "      <td>184306.0</td>\n",
       "      <td>188478.0</td>\n",
       "      <td>4274.0</td>\n",
       "      <td>79884.0</td>\n",
       "      <td>23819.0</td>\n",
       "      <td>105173.0</td>\n",
       "      <td>140610.0</td>\n",
       "      <td>23035.0</td>\n",
       "      <td>25054.0</td>\n",
       "      <td>71411.0</td>\n",
       "      <td>36092.0</td>\n",
       "      <td>33705.0</td>\n",
       "      <td>256316.0</td>\n",
       "      <td>92807.0</td>\n",
       "      <td>91423.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4        5         6  \\\n",
       "timestamp                                                                    \n",
       "2005-12-25 00:30:00  21429.0  179903.0  194116.0  537.0  10044.0  189947.0   \n",
       "2005-12-25 01:30:00  21124.0  174678.0  188478.0  524.0   9628.0  184306.0   \n",
       "\n",
       "zone_id                     7       8        9       10        11        12  \\\n",
       "timestamp                                                                     \n",
       "2005-12-25 00:30:00  194116.0  4456.0  80115.0  24745.0  109326.0  146826.0   \n",
       "2005-12-25 01:30:00  188478.0  4274.0  79884.0  23819.0  105173.0  140610.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2005-12-25 00:30:00  23890.0  26423.0  74062.0  37538.0  35435.0  263232.0   \n",
       "2005-12-25 01:30:00  23035.0  25054.0  71411.0  36092.0  33705.0  256316.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2005-12-25 00:30:00  96292.0  94372.0  \n",
       "2005-12-25 01:30:00  92807.0  91423.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p4_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_4_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p4_unlogged.index = period_4_X.index\n",
    "last_cycle_naive_p4_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28c7de-1dcb-41b4-ae11-c3f3804eea4e",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74993cb-87b4-421b-813c-574ac7570997",
   "metadata": {},
   "source": [
    "#### Period 5: 13 Feb 2006 - 19 Feb 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e75ec203-71d6-4b40-8386-8c25a123c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2006-02-13 00:30:00\") & (feature_matrix.index > \"2006-02-05 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2006-02-13 00:30:00\") & (load_wide_log.index > \"2006-02-05 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2006-02-26 00:30:00\") & (feature_matrix.index > \"2006-02-19 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2006-02-26 00:30:00\") & (load_wide_log.index > \"2006-02-19 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ffa2fd4-3680-4025-a048-117df2f96221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c45e297e-9ec8-4760-8b33-65238a2eb165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a4db693-522d-4121-89b0-0d4b6857d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_5_X = feature_matrix.loc[(feature_matrix.index >= \"2006-02-13 00:30:00\") & (feature_matrix.index <= \"2006-02-19 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_5_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_5_X = period_5_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_5 = period_5_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "044c95f5-323f-4b22-9a4e-bc18c095dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_5.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_5)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_5.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_5)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0810b9d8-7c1b-4c31-8b32-250c0705a8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-02-13 00:30:00</th>\n",
       "      <td>21452.619328</td>\n",
       "      <td>197400.547213</td>\n",
       "      <td>212995.585905</td>\n",
       "      <td>541.901326</td>\n",
       "      <td>9297.023787</td>\n",
       "      <td>206701.458471</td>\n",
       "      <td>212995.585905</td>\n",
       "      <td>4159.599170</td>\n",
       "      <td>66146.224903</td>\n",
       "      <td>30636.373837</td>\n",
       "      <td>116280.661018</td>\n",
       "      <td>151169.457921</td>\n",
       "      <td>24244.018647</td>\n",
       "      <td>26431.732481</td>\n",
       "      <td>70573.035123</td>\n",
       "      <td>37555.121103</td>\n",
       "      <td>38510.107960</td>\n",
       "      <td>267228.020762</td>\n",
       "      <td>93665.567680</td>\n",
       "      <td>99940.868270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13 01:30:00</th>\n",
       "      <td>21387.695577</td>\n",
       "      <td>192799.542447</td>\n",
       "      <td>208031.109739</td>\n",
       "      <td>517.119122</td>\n",
       "      <td>9116.947953</td>\n",
       "      <td>201932.439743</td>\n",
       "      <td>208031.109739</td>\n",
       "      <td>4053.017084</td>\n",
       "      <td>66515.473801</td>\n",
       "      <td>29848.697381</td>\n",
       "      <td>113949.818906</td>\n",
       "      <td>147184.148454</td>\n",
       "      <td>23638.496945</td>\n",
       "      <td>26365.806545</td>\n",
       "      <td>70054.051450</td>\n",
       "      <td>37592.367586</td>\n",
       "      <td>38419.363954</td>\n",
       "      <td>266397.079082</td>\n",
       "      <td>93611.669198</td>\n",
       "      <td>97857.735656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13 02:30:00</th>\n",
       "      <td>21911.045379</td>\n",
       "      <td>192310.595200</td>\n",
       "      <td>207503.558519</td>\n",
       "      <td>511.101791</td>\n",
       "      <td>9280.497945</td>\n",
       "      <td>201620.803547</td>\n",
       "      <td>207503.558519</td>\n",
       "      <td>4070.015655</td>\n",
       "      <td>66248.868070</td>\n",
       "      <td>29789.774908</td>\n",
       "      <td>114615.504914</td>\n",
       "      <td>147242.996711</td>\n",
       "      <td>23472.817509</td>\n",
       "      <td>26633.174636</td>\n",
       "      <td>70402.449263</td>\n",
       "      <td>38260.040994</td>\n",
       "      <td>39046.919120</td>\n",
       "      <td>271028.126436</td>\n",
       "      <td>95412.423331</td>\n",
       "      <td>97850.481783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13 03:30:00</th>\n",
       "      <td>23231.116238</td>\n",
       "      <td>197204.736666</td>\n",
       "      <td>212784.379298</td>\n",
       "      <td>528.284457</td>\n",
       "      <td>9872.678682</td>\n",
       "      <td>207112.341531</td>\n",
       "      <td>212784.379298</td>\n",
       "      <td>4235.146199</td>\n",
       "      <td>64828.688262</td>\n",
       "      <td>30777.957896</td>\n",
       "      <td>119298.559187</td>\n",
       "      <td>152738.992882</td>\n",
       "      <td>24006.097963</td>\n",
       "      <td>27591.759832</td>\n",
       "      <td>72334.476720</td>\n",
       "      <td>39985.443242</td>\n",
       "      <td>40746.476557</td>\n",
       "      <td>283923.119026</td>\n",
       "      <td>100098.969084</td>\n",
       "      <td>100662.152143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13 04:30:00</th>\n",
       "      <td>25359.121033</td>\n",
       "      <td>207617.962125</td>\n",
       "      <td>224020.311124</td>\n",
       "      <td>569.265829</td>\n",
       "      <td>10893.136007</td>\n",
       "      <td>218528.331212</td>\n",
       "      <td>224020.311124</td>\n",
       "      <td>4542.307608</td>\n",
       "      <td>62191.924455</td>\n",
       "      <td>32914.972882</td>\n",
       "      <td>128162.965154</td>\n",
       "      <td>163865.416221</td>\n",
       "      <td>25340.912617</td>\n",
       "      <td>29384.115435</td>\n",
       "      <td>76104.374125</td>\n",
       "      <td>42896.071298</td>\n",
       "      <td>43571.559195</td>\n",
       "      <td>305702.493210</td>\n",
       "      <td>107924.375714</td>\n",
       "      <td>106401.372144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-02-13 00:30:00  21452.619328  197400.547213  212995.585905   541.901326   \n",
       "2006-02-13 01:30:00  21387.695577  192799.542447  208031.109739   517.119122   \n",
       "2006-02-13 02:30:00  21911.045379  192310.595200  207503.558519   511.101791   \n",
       "2006-02-13 03:30:00  23231.116238  197204.736666  212784.379298   528.284457   \n",
       "2006-02-13 04:30:00  25359.121033  207617.962125  224020.311124   569.265829   \n",
       "\n",
       "                      Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-02-13 00:30:00   9297.023787  206701.458471  212995.585905  4159.599170   \n",
       "2006-02-13 01:30:00   9116.947953  201932.439743  208031.109739  4053.017084   \n",
       "2006-02-13 02:30:00   9280.497945  201620.803547  207503.558519  4070.015655   \n",
       "2006-02-13 03:30:00   9872.678682  207112.341531  212784.379298  4235.146199   \n",
       "2006-02-13 04:30:00  10893.136007  218528.331212  224020.311124  4542.307608   \n",
       "\n",
       "                      Zone_9_pred  Zone_10_pred   Zone_11_pred   Zone_12_pred  \\\n",
       "timestamp                                                                       \n",
       "2006-02-13 00:30:00  66146.224903  30636.373837  116280.661018  151169.457921   \n",
       "2006-02-13 01:30:00  66515.473801  29848.697381  113949.818906  147184.148454   \n",
       "2006-02-13 02:30:00  66248.868070  29789.774908  114615.504914  147242.996711   \n",
       "2006-02-13 03:30:00  64828.688262  30777.957896  119298.559187  152738.992882   \n",
       "2006-02-13 04:30:00  62191.924455  32914.972882  128162.965154  163865.416221   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-02-13 00:30:00  24244.018647  26431.732481  70573.035123  37555.121103   \n",
       "2006-02-13 01:30:00  23638.496945  26365.806545  70054.051450  37592.367586   \n",
       "2006-02-13 02:30:00  23472.817509  26633.174636  70402.449263  38260.040994   \n",
       "2006-02-13 03:30:00  24006.097963  27591.759832  72334.476720  39985.443242   \n",
       "2006-02-13 04:30:00  25340.912617  29384.115435  76104.374125  42896.071298   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred   Zone_19_pred   Zone_20_pred  \n",
       "timestamp                                                                       \n",
       "2006-02-13 00:30:00  38510.107960  267228.020762   93665.567680   99940.868270  \n",
       "2006-02-13 01:30:00  38419.363954  266397.079082   93611.669198   97857.735656  \n",
       "2006-02-13 02:30:00  39046.919120  271028.126436   95412.423331   97850.481783  \n",
       "2006-02-13 03:30:00  40746.476557  283923.119026  100098.969084  100662.152143  \n",
       "2006-02-13 04:30:00  43571.559195  305702.493210  107924.375714  106401.372144  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p5_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p5_mean_unlogged = np.exp(predictions_p5_mean)\n",
    "predictions_p5_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c677d8a-110d-47ff-9c50-dc9184baf8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-02-13 00:30:00</th>\n",
       "      <td>22108.0</td>\n",
       "      <td>173382.0</td>\n",
       "      <td>187079.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>8332.0</td>\n",
       "      <td>181713.0</td>\n",
       "      <td>187079.0</td>\n",
       "      <td>3964.0</td>\n",
       "      <td>64848.0</td>\n",
       "      <td>23557.0</td>\n",
       "      <td>93146.0</td>\n",
       "      <td>127480.0</td>\n",
       "      <td>23316.0</td>\n",
       "      <td>24632.0</td>\n",
       "      <td>70279.0</td>\n",
       "      <td>33329.0</td>\n",
       "      <td>36974.0</td>\n",
       "      <td>236617.0</td>\n",
       "      <td>92291.0</td>\n",
       "      <td>90099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13 01:30:00</th>\n",
       "      <td>21988.0</td>\n",
       "      <td>173426.0</td>\n",
       "      <td>187126.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>8288.0</td>\n",
       "      <td>181713.0</td>\n",
       "      <td>187126.0</td>\n",
       "      <td>3798.0</td>\n",
       "      <td>65478.0</td>\n",
       "      <td>23188.0</td>\n",
       "      <td>91117.0</td>\n",
       "      <td>124229.0</td>\n",
       "      <td>22799.0</td>\n",
       "      <td>24574.0</td>\n",
       "      <td>70199.0</td>\n",
       "      <td>33797.0</td>\n",
       "      <td>36221.0</td>\n",
       "      <td>235005.0</td>\n",
       "      <td>91260.0</td>\n",
       "      <td>88589.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2006-02-13 00:30:00  22108.0  173382.0  187079.0  510.0  8332.0  181713.0   \n",
       "2006-02-13 01:30:00  21988.0  173426.0  187126.0  502.0  8288.0  181713.0   \n",
       "\n",
       "zone_id                     7       8        9       10       11        12  \\\n",
       "timestamp                                                                    \n",
       "2006-02-13 00:30:00  187079.0  3964.0  64848.0  23557.0  93146.0  127480.0   \n",
       "2006-02-13 01:30:00  187126.0  3798.0  65478.0  23188.0  91117.0  124229.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2006-02-13 00:30:00  23316.0  24632.0  70279.0  33329.0  36974.0  236617.0   \n",
       "2006-02-13 01:30:00  22799.0  24574.0  70199.0  33797.0  36221.0  235005.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2006-02-13 00:30:00  92291.0  90099.0  \n",
       "2006-02-13 01:30:00  91260.0  88589.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p5_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_5_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p5_unlogged.index = period_5_X.index\n",
    "last_cycle_naive_p5_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131553aa-889f-4f9d-911a-c139aac9c3e9",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63287737-c356-4b83-a3e4-ca2768a99a0a",
   "metadata": {},
   "source": [
    "#### Period 6: 25 May 2006 - 31 May 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1a1ca19-ca39-4e99-9d94-b373c9b8b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2006-05-25 00:30:00\") & (feature_matrix.index > \"2006-05-17 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2006-05-25 00:30:00\") & (load_wide_log.index > \"2006-05-17 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2006-06-08 00:30:00\") & (feature_matrix.index > \"2006-05-31 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2006-06-08 00:30:00\") & (load_wide_log.index > \"2006-05-31 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcf1836f-b178-4a6f-a954-81b60b8a8fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a3863b5-8e77-42a3-9d13-8c9c22a89e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6f83a00-7f2b-4ee7-80f0-dc58218d3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_6_X = feature_matrix.loc[(feature_matrix.index >= \"2006-05-25 00:30:00\") & (feature_matrix.index <= \"2006-05-31 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_6_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_6_X = period_6_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_6 = period_6_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "080b91d5-ac1e-4e44-b6f4-e7de0cfeef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_6.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_6)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_6.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_6)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e09e829-da08-4202-ad0c-32446117eefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-05-25 00:30:00</th>\n",
       "      <td>10412.224387</td>\n",
       "      <td>99142.407845</td>\n",
       "      <td>106974.008513</td>\n",
       "      <td>322.115907</td>\n",
       "      <td>3644.838779</td>\n",
       "      <td>102840.689429</td>\n",
       "      <td>106974.008513</td>\n",
       "      <td>2187.398267</td>\n",
       "      <td>123708.090695</td>\n",
       "      <td>12961.052199</td>\n",
       "      <td>55301.429431</td>\n",
       "      <td>71778.446359</td>\n",
       "      <td>11910.238937</td>\n",
       "      <td>10358.310105</td>\n",
       "      <td>40682.313885</td>\n",
       "      <td>15092.070868</td>\n",
       "      <td>18252.368517</td>\n",
       "      <td>107611.985695</td>\n",
       "      <td>41315.395879</td>\n",
       "      <td>50953.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-25 01:30:00</th>\n",
       "      <td>8521.736062</td>\n",
       "      <td>81396.592418</td>\n",
       "      <td>87825.943855</td>\n",
       "      <td>277.443177</td>\n",
       "      <td>2704.281944</td>\n",
       "      <td>84097.806297</td>\n",
       "      <td>87825.943855</td>\n",
       "      <td>1938.026827</td>\n",
       "      <td>128844.640122</td>\n",
       "      <td>9859.075601</td>\n",
       "      <td>43157.850466</td>\n",
       "      <td>56388.289439</td>\n",
       "      <td>9915.103199</td>\n",
       "      <td>7688.012452</td>\n",
       "      <td>34147.715644</td>\n",
       "      <td>11822.373771</td>\n",
       "      <td>14105.472210</td>\n",
       "      <td>83145.832820</td>\n",
       "      <td>31993.427603</td>\n",
       "      <td>41876.726238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-25 02:30:00</th>\n",
       "      <td>7856.713370</td>\n",
       "      <td>75942.687704</td>\n",
       "      <td>81941.105141</td>\n",
       "      <td>261.989644</td>\n",
       "      <td>2414.944856</td>\n",
       "      <td>78325.582277</td>\n",
       "      <td>81941.105141</td>\n",
       "      <td>1861.323381</td>\n",
       "      <td>127149.461895</td>\n",
       "      <td>8921.827963</td>\n",
       "      <td>39072.461829</td>\n",
       "      <td>50664.681760</td>\n",
       "      <td>9261.402550</td>\n",
       "      <td>6757.383893</td>\n",
       "      <td>31785.473578</td>\n",
       "      <td>10664.794822</td>\n",
       "      <td>12763.451720</td>\n",
       "      <td>75008.272123</td>\n",
       "      <td>28890.042838</td>\n",
       "      <td>39096.880094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-25 03:30:00</th>\n",
       "      <td>7788.053065</td>\n",
       "      <td>75469.215693</td>\n",
       "      <td>81430.190685</td>\n",
       "      <td>264.758772</td>\n",
       "      <td>2406.418633</td>\n",
       "      <td>77840.776782</td>\n",
       "      <td>81430.190685</td>\n",
       "      <td>1896.750860</td>\n",
       "      <td>122308.552490</td>\n",
       "      <td>8785.184961</td>\n",
       "      <td>38419.740450</td>\n",
       "      <td>49454.198484</td>\n",
       "      <td>9361.916159</td>\n",
       "      <td>6588.527207</td>\n",
       "      <td>31589.980849</td>\n",
       "      <td>10512.493429</td>\n",
       "      <td>12491.911777</td>\n",
       "      <td>74278.061804</td>\n",
       "      <td>28677.383006</td>\n",
       "      <td>39291.660924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-25 04:30:00</th>\n",
       "      <td>8491.420505</td>\n",
       "      <td>82621.511310</td>\n",
       "      <td>89147.578486</td>\n",
       "      <td>289.587057</td>\n",
       "      <td>2774.003850</td>\n",
       "      <td>85383.603127</td>\n",
       "      <td>89147.578486</td>\n",
       "      <td>2062.411478</td>\n",
       "      <td>113977.810438</td>\n",
       "      <td>9866.106866</td>\n",
       "      <td>42608.499910</td>\n",
       "      <td>54136.234403</td>\n",
       "      <td>10435.097131</td>\n",
       "      <td>7399.862693</td>\n",
       "      <td>34235.082556</td>\n",
       "      <td>11668.711886</td>\n",
       "      <td>13806.239181</td>\n",
       "      <td>83445.481557</td>\n",
       "      <td>32260.519336</td>\n",
       "      <td>43639.831461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred   Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-05-25 00:30:00  10412.224387  99142.407845  106974.008513   322.115907   \n",
       "2006-05-25 01:30:00   8521.736062  81396.592418   87825.943855   277.443177   \n",
       "2006-05-25 02:30:00   7856.713370  75942.687704   81941.105141   261.989644   \n",
       "2006-05-25 03:30:00   7788.053065  75469.215693   81430.190685   264.758772   \n",
       "2006-05-25 04:30:00   8491.420505  82621.511310   89147.578486   289.587057   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-05-25 00:30:00  3644.838779  102840.689429  106974.008513  2187.398267   \n",
       "2006-05-25 01:30:00  2704.281944   84097.806297   87825.943855  1938.026827   \n",
       "2006-05-25 02:30:00  2414.944856   78325.582277   81941.105141  1861.323381   \n",
       "2006-05-25 03:30:00  2406.418633   77840.776782   81430.190685  1896.750860   \n",
       "2006-05-25 04:30:00  2774.003850   85383.603127   89147.578486  2062.411478   \n",
       "\n",
       "                       Zone_9_pred  Zone_10_pred  Zone_11_pred  Zone_12_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-05-25 00:30:00  123708.090695  12961.052199  55301.429431  71778.446359   \n",
       "2006-05-25 01:30:00  128844.640122   9859.075601  43157.850466  56388.289439   \n",
       "2006-05-25 02:30:00  127149.461895   8921.827963  39072.461829  50664.681760   \n",
       "2006-05-25 03:30:00  122308.552490   8785.184961  38419.740450  49454.198484   \n",
       "2006-05-25 04:30:00  113977.810438   9866.106866  42608.499910  54136.234403   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-05-25 00:30:00  11910.238937  10358.310105  40682.313885  15092.070868   \n",
       "2006-05-25 01:30:00   9915.103199   7688.012452  34147.715644  11822.373771   \n",
       "2006-05-25 02:30:00   9261.402550   6757.383893  31785.473578  10664.794822   \n",
       "2006-05-25 03:30:00   9361.916159   6588.527207  31589.980849  10512.493429   \n",
       "2006-05-25 04:30:00  10435.097131   7399.862693  34235.082556  11668.711886   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred  Zone_19_pred  Zone_20_pred  \n",
       "timestamp                                                                     \n",
       "2006-05-25 00:30:00  18252.368517  107611.985695  41315.395879  50953.042900  \n",
       "2006-05-25 01:30:00  14105.472210   83145.832820  31993.427603  41876.726238  \n",
       "2006-05-25 02:30:00  12763.451720   75008.272123  28890.042838  39096.880094  \n",
       "2006-05-25 03:30:00  12491.911777   74278.061804  28677.383006  39291.660924  \n",
       "2006-05-25 04:30:00  13806.239181   83445.481557  32260.519336  43639.831461  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p6_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p6_mean_unlogged = np.exp(predictions_p6_mean)\n",
    "predictions_p6_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed4360a5-178f-4438-a1f7-f443de68ea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-05-25 00:30:00</th>\n",
       "      <td>11268.0</td>\n",
       "      <td>128006.0</td>\n",
       "      <td>138119.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>132037.0</td>\n",
       "      <td>138119.0</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>80703.0</td>\n",
       "      <td>18125.0</td>\n",
       "      <td>62918.0</td>\n",
       "      <td>73969.0</td>\n",
       "      <td>12821.0</td>\n",
       "      <td>10846.0</td>\n",
       "      <td>41124.0</td>\n",
       "      <td>14890.0</td>\n",
       "      <td>23115.0</td>\n",
       "      <td>118544.0</td>\n",
       "      <td>44021.0</td>\n",
       "      <td>62178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-25 01:30:00</th>\n",
       "      <td>10635.0</td>\n",
       "      <td>123694.0</td>\n",
       "      <td>133467.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>127418.0</td>\n",
       "      <td>133467.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>69027.0</td>\n",
       "      <td>16771.0</td>\n",
       "      <td>58922.0</td>\n",
       "      <td>67396.0</td>\n",
       "      <td>12212.0</td>\n",
       "      <td>9960.0</td>\n",
       "      <td>38955.0</td>\n",
       "      <td>14050.0</td>\n",
       "      <td>21825.0</td>\n",
       "      <td>110073.0</td>\n",
       "      <td>41008.0</td>\n",
       "      <td>59775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2006-05-25 00:30:00  11268.0  128006.0  138119.0  346.0  4030.0  132037.0   \n",
       "2006-05-25 01:30:00  10635.0  123694.0  133467.0  331.0  3723.0  127418.0   \n",
       "\n",
       "zone_id                     7       8        9       10       11       12  \\\n",
       "timestamp                                                                   \n",
       "2006-05-25 00:30:00  138119.0  2319.0  80703.0  18125.0  62918.0  73969.0   \n",
       "2006-05-25 01:30:00  133467.0  2224.0  69027.0  16771.0  58922.0  67396.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2006-05-25 00:30:00  12821.0  10846.0  41124.0  14890.0  23115.0  118544.0   \n",
       "2006-05-25 01:30:00  12212.0   9960.0  38955.0  14050.0  21825.0  110073.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2006-05-25 00:30:00  44021.0  62178.0  \n",
       "2006-05-25 01:30:00  41008.0  59775.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p6_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_6_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p6_unlogged.index = period_6_X.index\n",
    "last_cycle_naive_p6_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4664622e-b80e-4748-9a36-eb34d16c6ed3",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856a34c-1cad-4443-be2e-0606588bde56",
   "metadata": {},
   "source": [
    "#### Period 7: 02 Aug 2006 - 08 Aug 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c52f4a52-2655-4e32-9330-e068ff717d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2006-08-02 00:30:00\") & (feature_matrix.index > \"2006-07-25 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2006-08-02 00:30:00\") & (load_wide_log.index > \"2006-07-25 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2006-08-16 00:30:00\") & (feature_matrix.index > \"2006-08-08 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2006-08-16 00:30:00\") & (load_wide_log.index > \"2006-08-08 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "949e3b81-4714-429e-83a7-bab763ff4650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8dc3684-2ab9-4930-b901-39109b78c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83974df3-0401-4002-be96-dd64890f6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_7_X = feature_matrix.loc[(feature_matrix.index >= \"2006-08-02 00:30:00\") & (feature_matrix.index <= \"2006-08-08 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_7_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_7_X = period_7_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_7 = period_7_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bf4aee5-14f0-4765-b38f-2dbb5e9c1cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_7.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_7)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_7.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_7)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b19bb12-c9fb-481c-b483-ca0c8e37292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-08-02 00:30:00</th>\n",
       "      <td>22263.173983</td>\n",
       "      <td>189471.784514</td>\n",
       "      <td>204440.480273</td>\n",
       "      <td>413.564144</td>\n",
       "      <td>7951.321190</td>\n",
       "      <td>197404.977538</td>\n",
       "      <td>204440.480273</td>\n",
       "      <td>3192.990675</td>\n",
       "      <td>102967.240815</td>\n",
       "      <td>34004.605391</td>\n",
       "      <td>123666.676419</td>\n",
       "      <td>152914.692524</td>\n",
       "      <td>18721.601404</td>\n",
       "      <td>23002.170301</td>\n",
       "      <td>73725.158485</td>\n",
       "      <td>30888.022328</td>\n",
       "      <td>38678.890407</td>\n",
       "      <td>227521.843538</td>\n",
       "      <td>90539.272036</td>\n",
       "      <td>95629.972864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-02 01:30:00</th>\n",
       "      <td>19692.746676</td>\n",
       "      <td>175310.881411</td>\n",
       "      <td>189160.802303</td>\n",
       "      <td>371.742922</td>\n",
       "      <td>6896.625839</td>\n",
       "      <td>182142.616152</td>\n",
       "      <td>189160.802303</td>\n",
       "      <td>2876.443971</td>\n",
       "      <td>97873.266129</td>\n",
       "      <td>31131.278528</td>\n",
       "      <td>110811.649694</td>\n",
       "      <td>134140.038793</td>\n",
       "      <td>16771.486267</td>\n",
       "      <td>19966.100599</td>\n",
       "      <td>66540.430593</td>\n",
       "      <td>27355.578331</td>\n",
       "      <td>35298.274875</td>\n",
       "      <td>200430.742033</td>\n",
       "      <td>79640.550664</td>\n",
       "      <td>86720.723267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-02 02:30:00</th>\n",
       "      <td>17898.544942</td>\n",
       "      <td>165566.116388</td>\n",
       "      <td>178646.146950</td>\n",
       "      <td>345.459776</td>\n",
       "      <td>6204.861247</td>\n",
       "      <td>171666.302158</td>\n",
       "      <td>178646.146950</td>\n",
       "      <td>2681.831628</td>\n",
       "      <td>93226.558341</td>\n",
       "      <td>29167.496922</td>\n",
       "      <td>101921.900085</td>\n",
       "      <td>120987.675559</td>\n",
       "      <td>15536.856513</td>\n",
       "      <td>17846.313290</td>\n",
       "      <td>61472.955832</td>\n",
       "      <td>24925.798435</td>\n",
       "      <td>32834.601625</td>\n",
       "      <td>181903.227119</td>\n",
       "      <td>72195.209674</td>\n",
       "      <td>80930.393775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-02 03:30:00</th>\n",
       "      <td>16921.895186</td>\n",
       "      <td>160873.125109</td>\n",
       "      <td>173582.372439</td>\n",
       "      <td>336.036383</td>\n",
       "      <td>5869.351473</td>\n",
       "      <td>166618.401142</td>\n",
       "      <td>173582.372439</td>\n",
       "      <td>2608.096218</td>\n",
       "      <td>91112.915405</td>\n",
       "      <td>28260.319227</td>\n",
       "      <td>97416.141548</td>\n",
       "      <td>113865.900566</td>\n",
       "      <td>15071.171779</td>\n",
       "      <td>16689.352788</td>\n",
       "      <td>58818.497689</td>\n",
       "      <td>23680.853115</td>\n",
       "      <td>31450.624043</td>\n",
       "      <td>172492.319884</td>\n",
       "      <td>68389.973071</td>\n",
       "      <td>78556.317186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-02 04:30:00</th>\n",
       "      <td>16314.113470</td>\n",
       "      <td>157439.808494</td>\n",
       "      <td>169877.795058</td>\n",
       "      <td>341.500828</td>\n",
       "      <td>5726.604923</td>\n",
       "      <td>163058.858510</td>\n",
       "      <td>169877.795058</td>\n",
       "      <td>2613.633062</td>\n",
       "      <td>91728.422019</td>\n",
       "      <td>27642.898757</td>\n",
       "      <td>94529.923261</td>\n",
       "      <td>109557.334266</td>\n",
       "      <td>15135.529493</td>\n",
       "      <td>16110.392445</td>\n",
       "      <td>57335.046658</td>\n",
       "      <td>23091.209048</td>\n",
       "      <td>30438.153476</td>\n",
       "      <td>167777.715565</td>\n",
       "      <td>66416.840823</td>\n",
       "      <td>77636.149418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-08-02 00:30:00  22263.173983  189471.784514  204440.480273   413.564144   \n",
       "2006-08-02 01:30:00  19692.746676  175310.881411  189160.802303   371.742922   \n",
       "2006-08-02 02:30:00  17898.544942  165566.116388  178646.146950   345.459776   \n",
       "2006-08-02 03:30:00  16921.895186  160873.125109  173582.372439   336.036383   \n",
       "2006-08-02 04:30:00  16314.113470  157439.808494  169877.795058   341.500828   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-08-02 00:30:00  7951.321190  197404.977538  204440.480273  3192.990675   \n",
       "2006-08-02 01:30:00  6896.625839  182142.616152  189160.802303  2876.443971   \n",
       "2006-08-02 02:30:00  6204.861247  171666.302158  178646.146950  2681.831628   \n",
       "2006-08-02 03:30:00  5869.351473  166618.401142  173582.372439  2608.096218   \n",
       "2006-08-02 04:30:00  5726.604923  163058.858510  169877.795058  2613.633062   \n",
       "\n",
       "                       Zone_9_pred  Zone_10_pred   Zone_11_pred  \\\n",
       "timestamp                                                         \n",
       "2006-08-02 00:30:00  102967.240815  34004.605391  123666.676419   \n",
       "2006-08-02 01:30:00   97873.266129  31131.278528  110811.649694   \n",
       "2006-08-02 02:30:00   93226.558341  29167.496922  101921.900085   \n",
       "2006-08-02 03:30:00   91112.915405  28260.319227   97416.141548   \n",
       "2006-08-02 04:30:00   91728.422019  27642.898757   94529.923261   \n",
       "\n",
       "                      Zone_12_pred  Zone_13_pred  Zone_14_pred  Zone_15_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-08-02 00:30:00  152914.692524  18721.601404  23002.170301  73725.158485   \n",
       "2006-08-02 01:30:00  134140.038793  16771.486267  19966.100599  66540.430593   \n",
       "2006-08-02 02:30:00  120987.675559  15536.856513  17846.313290  61472.955832   \n",
       "2006-08-02 03:30:00  113865.900566  15071.171779  16689.352788  58818.497689   \n",
       "2006-08-02 04:30:00  109557.334266  15135.529493  16110.392445  57335.046658   \n",
       "\n",
       "                     Zone_16_pred  Zone_17_pred   Zone_18_pred  Zone_19_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-08-02 00:30:00  30888.022328  38678.890407  227521.843538  90539.272036   \n",
       "2006-08-02 01:30:00  27355.578331  35298.274875  200430.742033  79640.550664   \n",
       "2006-08-02 02:30:00  24925.798435  32834.601625  181903.227119  72195.209674   \n",
       "2006-08-02 03:30:00  23680.853115  31450.624043  172492.319884  68389.973071   \n",
       "2006-08-02 04:30:00  23091.209048  30438.153476  167777.715565  66416.840823   \n",
       "\n",
       "                     Zone_20_pred  \n",
       "timestamp                          \n",
       "2006-08-02 00:30:00  95629.972864  \n",
       "2006-08-02 01:30:00  86720.723267  \n",
       "2006-08-02 02:30:00  80930.393775  \n",
       "2006-08-02 03:30:00  78556.317186  \n",
       "2006-08-02 04:30:00  77636.149418  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p7_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p7_mean_unlogged = np.exp(predictions_p7_mean)\n",
    "predictions_p7_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3d9ab73-4efc-4e97-94ef-e4e715314b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-08-02 00:30:00</th>\n",
       "      <td>16349.0</td>\n",
       "      <td>161874.0</td>\n",
       "      <td>174662.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>6234.0</td>\n",
       "      <td>168108.0</td>\n",
       "      <td>174662.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>93450.0</td>\n",
       "      <td>26556.0</td>\n",
       "      <td>99613.0</td>\n",
       "      <td>123715.0</td>\n",
       "      <td>15541.0</td>\n",
       "      <td>17521.0</td>\n",
       "      <td>55921.0</td>\n",
       "      <td>24984.0</td>\n",
       "      <td>31938.0</td>\n",
       "      <td>177341.0</td>\n",
       "      <td>66148.0</td>\n",
       "      <td>77538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-02 01:30:00</th>\n",
       "      <td>14609.0</td>\n",
       "      <td>154462.0</td>\n",
       "      <td>166665.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>160077.0</td>\n",
       "      <td>166665.0</td>\n",
       "      <td>2502.0</td>\n",
       "      <td>93660.0</td>\n",
       "      <td>24888.0</td>\n",
       "      <td>92294.0</td>\n",
       "      <td>110378.0</td>\n",
       "      <td>14234.0</td>\n",
       "      <td>15618.0</td>\n",
       "      <td>51720.0</td>\n",
       "      <td>22532.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>161397.0</td>\n",
       "      <td>60256.0</td>\n",
       "      <td>72783.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2006-08-02 00:30:00  16349.0  161874.0  174662.0  402.0  6234.0  168108.0   \n",
       "2006-08-02 01:30:00  14609.0  154462.0  166665.0  376.0  5615.0  160077.0   \n",
       "\n",
       "zone_id                     7       8        9       10       11        12  \\\n",
       "timestamp                                                                    \n",
       "2006-08-02 00:30:00  174662.0  2730.0  93450.0  26556.0  99613.0  123715.0   \n",
       "2006-08-02 01:30:00  166665.0  2502.0  93660.0  24888.0  92294.0  110378.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2006-08-02 00:30:00  15541.0  17521.0  55921.0  24984.0  31938.0  177341.0   \n",
       "2006-08-02 01:30:00  14234.0  15618.0  51720.0  22532.0  29547.0  161397.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2006-08-02 00:30:00  66148.0  77538.0  \n",
       "2006-08-02 01:30:00  60256.0  72783.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p7_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_7_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p7_unlogged.index = period_7_X.index\n",
    "last_cycle_naive_p7_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273102bb-ad12-41f7-aeba-6baa169bf456",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42506ce2-292a-4dfb-a978-b1bfd7ecf96b",
   "metadata": {},
   "source": [
    "#### Period 8: 22 Nov 2006 - 28 Nov 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72d0d3ad-ee33-4c39-ace0-bfe79c4d75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data 1 (1 weeks)\n",
    "train_p1_X = feature_matrix.loc[(feature_matrix.index < \"2006-11-22 00:30:00\") & (feature_matrix.index > \"2006-11-13 23:30:00\"),:]\n",
    "train_p1_y = load_wide_log.loc[(load_wide_log.index < \"2006-11-22 00:30:00\") & (load_wide_log.index > \"2006-11-13 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Creating training data 2 (1 weeks)\n",
    "train_p2_X = feature_matrix.loc[(feature_matrix.index < \"2006-12-06 00:30:00\") & (feature_matrix.index > \"2006-11-28 23:30:00\"),:]\n",
    "train_p2_y = load_wide_log.loc[(load_wide_log.index < \"2006-12-06 00:30:00\") & (load_wide_log.index > \"2006-11-28 23:30:00\"), list(range(1,21,1))]\n",
    "\n",
    "# Adding periodicities\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "periodicity = Fourier(period=24, order=2) # daily cycle i.e. 24 hours, 2 harmonics\n",
    "\n",
    "# Defining the sine wave (training set 1)\n",
    "dp1 = DeterministicProcess(\n",
    "    index=train_p1_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves1 = dp1.in_sample()\n",
    "\n",
    "# Defining the sine wave (training set 2)\n",
    "dp2 = DeterministicProcess(\n",
    "    index=train_p2_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves2 = dp2.in_sample()\n",
    "\n",
    "# Combining fourier terms with other variables\n",
    "train_p1_X = train_p1_X.merge(waves1, left_index=True, right_index=True, how='left')\n",
    "train_p2_X = train_p2_X.merge(waves2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c601b5c0-0056-4313-b5e6-7f49aac8e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 1 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train1 = train_p1_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_1 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p1_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p1_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train1, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_1[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95f9eb61-f190-45a8-9b6f-1ae35e5b7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "  -> Finished fitting model for: 1\n",
      "  -> Finished fitting model for: 2\n",
      "  -> Finished fitting model for: 3\n",
      "  -> Finished fitting model for: 4\n",
      "  -> Finished fitting model for: 5\n",
      "  -> Finished fitting model for: 6\n",
      "  -> Finished fitting model for: 7\n",
      "  -> Finished fitting model for: 8\n",
      "  -> Finished fitting model for: 9\n",
      "  -> Finished fitting model for: 10\n",
      "  -> Finished fitting model for: 11\n",
      "  -> Finished fitting model for: 12\n",
      "  -> Finished fitting model for: 13\n",
      "  -> Finished fitting model for: 14\n",
      "  -> Finished fitting model for: 15\n",
      "  -> Finished fitting model for: 16\n",
      "  -> Finished fitting model for: 17\n",
      "  -> Finished fitting model for: 18\n",
      "  -> Finished fitting model for: 19\n",
      "  -> Finished fitting model for: 20\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fitting Linear Regression Model (all zones) - training set 2 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train2 = train_p2_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]\n",
    "\n",
    "# Creating dictionary to store the fitted models\n",
    "fitted_models_set_2 = {}\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Looping through each target column\n",
    "for zone in list(train_p2_y.columns):\n",
    "    \n",
    "    # Extract the current target vector (y)\n",
    "    y = train_p2_y[zone]\n",
    "    \n",
    "    # 1. Instantiate the model\n",
    "    # A new model object is created for each iteration\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 2. Fit the model\n",
    "    # Train the model using the common features (X) and the current target (y)\n",
    "    model.fit(X_train2, y)\n",
    "    \n",
    "    # 3. Store the fitted model in the dictionary\n",
    "    fitted_models_set_2[zone] = model\n",
    "    \n",
    "    print(f\"  -> Finished fitting model for: {zone}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2746e88-55f4-4204-b0c8-7f79d13fde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature space dedicated to period 1\n",
    "period_8_X = feature_matrix.loc[(feature_matrix.index >= \"2006-11-22 00:30:00\") & (feature_matrix.index <= \"2006-11-28 23:30:00\"),:]\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=period_8_X.index,\n",
    "    period=None,         # It's not defined so that frequency can be read from the index\n",
    "    constant=False,      # defined later\n",
    "    order=1,             # linear trend not required since seasonal diff made the series stationary\n",
    "    seasonal=False,      # no seasonal dummies\n",
    "    additional_terms=[periodicity], # 2 seperate waves will be generated\n",
    "    drop=True            # if perfect collinearity exists, the terms can be dropped\n",
    ")\n",
    "\n",
    "waves = dp.in_sample()\n",
    "period_8_X = period_8_X.merge(waves, left_index=True, right_index=True, how='left')\n",
    "\n",
    "X_period_8 = period_8_X[['CDK', 'HDK', 'trend', 'sin(1,24)', 'cos(1,24)', 'sin(2,24)', 'cos(2,24)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee45173e-ea2e-404a-ba48-487dd27dd800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 1 complete!\n",
      "  -> Added column: Zone_1_pred\n",
      "  -> Added column: Zone_2_pred\n",
      "  -> Added column: Zone_3_pred\n",
      "  -> Added column: Zone_4_pred\n",
      "  -> Added column: Zone_5_pred\n",
      "  -> Added column: Zone_6_pred\n",
      "  -> Added column: Zone_7_pred\n",
      "  -> Added column: Zone_8_pred\n",
      "  -> Added column: Zone_9_pred\n",
      "  -> Added column: Zone_10_pred\n",
      "  -> Added column: Zone_11_pred\n",
      "  -> Added column: Zone_12_pred\n",
      "  -> Added column: Zone_13_pred\n",
      "  -> Added column: Zone_14_pred\n",
      "  -> Added column: Zone_15_pred\n",
      "  -> Added column: Zone_16_pred\n",
      "  -> Added column: Zone_17_pred\n",
      "  -> Added column: Zone_18_pred\n",
      "  -> Added column: Zone_19_pred\n",
      "  -> Added column: Zone_20_pred\n",
      "Prediction generation from training set 2 complete!\n"
     ]
    }
   ],
   "source": [
    "# Predicting load value per zone - from training set 1 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_1 = pd.DataFrame(index=X_period_8.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_1.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_8)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_1[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 1 complete!\")\n",
    "\n",
    "\n",
    "# Predicting load value per zone - from training set 2 models\n",
    "\n",
    "# Initializing an empty DataFrame with the correct index\n",
    "predictions_set_2 = pd.DataFrame(index=X_period_8.index)\n",
    "\n",
    "# Loop through the dictionary items\n",
    "for zone, model in fitted_models_set_2.items():\n",
    "    \n",
    "    # 1. Generate Predictions\n",
    "    # This returns a NumPy array of predicted values\n",
    "    predictions_array = model.predict(X_period_8)\n",
    "    \n",
    "    # 2. Assign the predictions array as a new column\n",
    "    # The new column is named 'Predicted_Target_X'\n",
    "    column_name = f'Zone_{zone}_pred'\n",
    "    \n",
    "    # Pandas should match the array to the DataFrame's existing index\n",
    "    predictions_set_2[column_name] = predictions_array\n",
    "    \n",
    "    print(f\"  -> Added column: {column_name}\")\n",
    "\n",
    "print(\"Prediction generation from training set 2 complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb25d57d-4c0e-4349-b712-a350c93e82be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone_1_pred</th>\n",
       "      <th>Zone_2_pred</th>\n",
       "      <th>Zone_3_pred</th>\n",
       "      <th>Zone_4_pred</th>\n",
       "      <th>Zone_5_pred</th>\n",
       "      <th>Zone_6_pred</th>\n",
       "      <th>Zone_7_pred</th>\n",
       "      <th>Zone_8_pred</th>\n",
       "      <th>Zone_9_pred</th>\n",
       "      <th>Zone_10_pred</th>\n",
       "      <th>Zone_11_pred</th>\n",
       "      <th>Zone_12_pred</th>\n",
       "      <th>Zone_13_pred</th>\n",
       "      <th>Zone_14_pred</th>\n",
       "      <th>Zone_15_pred</th>\n",
       "      <th>Zone_16_pred</th>\n",
       "      <th>Zone_17_pred</th>\n",
       "      <th>Zone_18_pred</th>\n",
       "      <th>Zone_19_pred</th>\n",
       "      <th>Zone_20_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-11-22 00:30:00</th>\n",
       "      <td>15783.489499</td>\n",
       "      <td>146172.840846</td>\n",
       "      <td>157720.744196</td>\n",
       "      <td>474.708340</td>\n",
       "      <td>6095.800222</td>\n",
       "      <td>152439.268248</td>\n",
       "      <td>157720.744196</td>\n",
       "      <td>3230.468424</td>\n",
       "      <td>81314.748203</td>\n",
       "      <td>18795.723026</td>\n",
       "      <td>82707.080006</td>\n",
       "      <td>94286.497431</td>\n",
       "      <td>18843.340671</td>\n",
       "      <td>17601.897266</td>\n",
       "      <td>57088.677932</td>\n",
       "      <td>23915.053434</td>\n",
       "      <td>28889.731494</td>\n",
       "      <td>183473.916523</td>\n",
       "      <td>71572.710025</td>\n",
       "      <td>80522.953700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-22 01:30:00</th>\n",
       "      <td>15002.661790</td>\n",
       "      <td>140229.302822</td>\n",
       "      <td>151307.672774</td>\n",
       "      <td>444.773730</td>\n",
       "      <td>5696.561111</td>\n",
       "      <td>146075.571198</td>\n",
       "      <td>151307.672774</td>\n",
       "      <td>3073.173672</td>\n",
       "      <td>82281.776169</td>\n",
       "      <td>17811.133407</td>\n",
       "      <td>77448.528427</td>\n",
       "      <td>87017.689959</td>\n",
       "      <td>17736.171334</td>\n",
       "      <td>16525.675036</td>\n",
       "      <td>54483.526680</td>\n",
       "      <td>22563.235799</td>\n",
       "      <td>27546.158176</td>\n",
       "      <td>173083.866452</td>\n",
       "      <td>67291.865322</td>\n",
       "      <td>76773.532601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-22 02:30:00</th>\n",
       "      <td>14854.509460</td>\n",
       "      <td>138550.615280</td>\n",
       "      <td>149496.385266</td>\n",
       "      <td>434.522447</td>\n",
       "      <td>5630.529077</td>\n",
       "      <td>144321.972268</td>\n",
       "      <td>149496.385266</td>\n",
       "      <td>3036.869961</td>\n",
       "      <td>80565.610026</td>\n",
       "      <td>17536.699215</td>\n",
       "      <td>75650.523675</td>\n",
       "      <td>84148.407029</td>\n",
       "      <td>17201.548234</td>\n",
       "      <td>15992.021349</td>\n",
       "      <td>53061.644731</td>\n",
       "      <td>21971.168881</td>\n",
       "      <td>27013.600327</td>\n",
       "      <td>169324.409739</td>\n",
       "      <td>65456.286025</td>\n",
       "      <td>75396.083844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-22 03:30:00</th>\n",
       "      <td>15284.070603</td>\n",
       "      <td>141073.379158</td>\n",
       "      <td>152218.468238</td>\n",
       "      <td>443.148044</td>\n",
       "      <td>5860.977658</td>\n",
       "      <td>147076.335155</td>\n",
       "      <td>152218.468238</td>\n",
       "      <td>3109.085192</td>\n",
       "      <td>77173.361617</td>\n",
       "      <td>17948.967176</td>\n",
       "      <td>77119.925459</td>\n",
       "      <td>85318.537190</td>\n",
       "      <td>17213.224730</td>\n",
       "      <td>15909.777511</td>\n",
       "      <td>52746.817116</td>\n",
       "      <td>22015.321007</td>\n",
       "      <td>27241.652279</td>\n",
       "      <td>171437.373496</td>\n",
       "      <td>65699.218702</td>\n",
       "      <td>76236.388094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-22 04:30:00</th>\n",
       "      <td>16337.557517</td>\n",
       "      <td>147752.122284</td>\n",
       "      <td>159424.858714</td>\n",
       "      <td>470.835385</td>\n",
       "      <td>6398.529197</td>\n",
       "      <td>154300.942447</td>\n",
       "      <td>159424.858714</td>\n",
       "      <td>3289.500665</td>\n",
       "      <td>73197.524071</td>\n",
       "      <td>19004.214232</td>\n",
       "      <td>81969.036468</td>\n",
       "      <td>90643.333522</td>\n",
       "      <td>17876.217383</td>\n",
       "      <td>16402.967952</td>\n",
       "      <td>53904.151798</td>\n",
       "      <td>22888.561901</td>\n",
       "      <td>28304.386777</td>\n",
       "      <td>180519.431997</td>\n",
       "      <td>68485.304135</td>\n",
       "      <td>79453.587607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zone_1_pred    Zone_2_pred    Zone_3_pred  Zone_4_pred  \\\n",
       "timestamp                                                                      \n",
       "2006-11-22 00:30:00  15783.489499  146172.840846  157720.744196   474.708340   \n",
       "2006-11-22 01:30:00  15002.661790  140229.302822  151307.672774   444.773730   \n",
       "2006-11-22 02:30:00  14854.509460  138550.615280  149496.385266   434.522447   \n",
       "2006-11-22 03:30:00  15284.070603  141073.379158  152218.468238   443.148044   \n",
       "2006-11-22 04:30:00  16337.557517  147752.122284  159424.858714   470.835385   \n",
       "\n",
       "                     Zone_5_pred    Zone_6_pred    Zone_7_pred  Zone_8_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-11-22 00:30:00  6095.800222  152439.268248  157720.744196  3230.468424   \n",
       "2006-11-22 01:30:00  5696.561111  146075.571198  151307.672774  3073.173672   \n",
       "2006-11-22 02:30:00  5630.529077  144321.972268  149496.385266  3036.869961   \n",
       "2006-11-22 03:30:00  5860.977658  147076.335155  152218.468238  3109.085192   \n",
       "2006-11-22 04:30:00  6398.529197  154300.942447  159424.858714  3289.500665   \n",
       "\n",
       "                      Zone_9_pred  Zone_10_pred  Zone_11_pred  Zone_12_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-11-22 00:30:00  81314.748203  18795.723026  82707.080006  94286.497431   \n",
       "2006-11-22 01:30:00  82281.776169  17811.133407  77448.528427  87017.689959   \n",
       "2006-11-22 02:30:00  80565.610026  17536.699215  75650.523675  84148.407029   \n",
       "2006-11-22 03:30:00  77173.361617  17948.967176  77119.925459  85318.537190   \n",
       "2006-11-22 04:30:00  73197.524071  19004.214232  81969.036468  90643.333522   \n",
       "\n",
       "                     Zone_13_pred  Zone_14_pred  Zone_15_pred  Zone_16_pred  \\\n",
       "timestamp                                                                     \n",
       "2006-11-22 00:30:00  18843.340671  17601.897266  57088.677932  23915.053434   \n",
       "2006-11-22 01:30:00  17736.171334  16525.675036  54483.526680  22563.235799   \n",
       "2006-11-22 02:30:00  17201.548234  15992.021349  53061.644731  21971.168881   \n",
       "2006-11-22 03:30:00  17213.224730  15909.777511  52746.817116  22015.321007   \n",
       "2006-11-22 04:30:00  17876.217383  16402.967952  53904.151798  22888.561901   \n",
       "\n",
       "                     Zone_17_pred   Zone_18_pred  Zone_19_pred  Zone_20_pred  \n",
       "timestamp                                                                     \n",
       "2006-11-22 00:30:00  28889.731494  183473.916523  71572.710025  80522.953700  \n",
       "2006-11-22 01:30:00  27546.158176  173083.866452  67291.865322  76773.532601  \n",
       "2006-11-22 02:30:00  27013.600327  169324.409739  65456.286025  75396.083844  \n",
       "2006-11-22 03:30:00  27241.652279  171437.373496  65699.218702  76236.388094  \n",
       "2006-11-22 04:30:00  28304.386777  180519.431997  68485.304135  79453.587607  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Prediction\n",
    "predictions_p8_mean = (predictions_set_1+predictions_set_2)/2\n",
    "\n",
    "# Undoing log transformation for original predictions\n",
    "predictions_p8_mean_unlogged = np.exp(predictions_p8_mean)\n",
    "predictions_p8_mean_unlogged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "163830c1-c1f7-45ea-999c-151fd5b3f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-11-22 00:30:00</th>\n",
       "      <td>13684.0</td>\n",
       "      <td>135868.0</td>\n",
       "      <td>146602.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>4695.0</td>\n",
       "      <td>140563.0</td>\n",
       "      <td>146602.0</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>35259.0</td>\n",
       "      <td>17730.0</td>\n",
       "      <td>71808.0</td>\n",
       "      <td>80241.0</td>\n",
       "      <td>16972.0</td>\n",
       "      <td>12639.0</td>\n",
       "      <td>49360.0</td>\n",
       "      <td>17784.0</td>\n",
       "      <td>25334.0</td>\n",
       "      <td>139865.0</td>\n",
       "      <td>58657.0</td>\n",
       "      <td>73176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-22 01:30:00</th>\n",
       "      <td>13530.0</td>\n",
       "      <td>133060.0</td>\n",
       "      <td>143573.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>4566.0</td>\n",
       "      <td>137626.0</td>\n",
       "      <td>143573.0</td>\n",
       "      <td>2698.0</td>\n",
       "      <td>55671.0</td>\n",
       "      <td>17137.0</td>\n",
       "      <td>68911.0</td>\n",
       "      <td>76321.0</td>\n",
       "      <td>16737.0</td>\n",
       "      <td>12242.0</td>\n",
       "      <td>48467.0</td>\n",
       "      <td>17557.0</td>\n",
       "      <td>24838.0</td>\n",
       "      <td>138431.0</td>\n",
       "      <td>58346.0</td>\n",
       "      <td>71566.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                    1         2         3      4       5         6  \\\n",
       "timestamp                                                                   \n",
       "2006-11-22 00:30:00  13684.0  135868.0  146602.0  475.0  4695.0  140563.0   \n",
       "2006-11-22 01:30:00  13530.0  133060.0  143573.0  461.0  4566.0  137626.0   \n",
       "\n",
       "zone_id                     7       8        9       10       11       12  \\\n",
       "timestamp                                                                   \n",
       "2006-11-22 00:30:00  146602.0  2757.0  35259.0  17730.0  71808.0  80241.0   \n",
       "2006-11-22 01:30:00  143573.0  2698.0  55671.0  17137.0  68911.0  76321.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2006-11-22 00:30:00  16972.0  12639.0  49360.0  17784.0  25334.0  139865.0   \n",
       "2006-11-22 01:30:00  16737.0  12242.0  48467.0  17557.0  24838.0  138431.0   \n",
       "\n",
       "zone_id                   19       20  \n",
       "timestamp                              \n",
       "2006-11-22 00:30:00  58657.0  73176.0  \n",
       "2006-11-22 01:30:00  58346.0  71566.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best naive method found: Repeating last cycle (unlogged)\n",
    "last_cycle_naive_p8_unlogged = np.exp(\n",
    "    train_p1_y[-len(period_8_X):]\n",
    ")\n",
    "\n",
    "# Reset index (correcting timestamp)\n",
    "last_cycle_naive_p8_unlogged.index = period_8_X.index\n",
    "last_cycle_naive_p8_unlogged[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f96a3-8fb5-441d-964e-2941089ff211",
   "metadata": {},
   "source": [
    "For fair comparison across grids with different scales, r2_score and mape make the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce406cd-71b4-4645-aaa3-0cc1423b0ba6",
   "metadata": {},
   "source": [
    "### Performance Comparison\n",
    "Performance is compared with actual load values as well as competition's benchmarked values for the missing 8 weeks. For fair comparison R2 score and MAPE are used as error metrics since they are not dependent on scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e26b32-22d1-4226-a3bd-8c0d4b821122",
   "metadata": {},
   "source": [
    "#### Reading Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05d255e7-4757-41df-b403-2721b5974867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>...</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "      <th>h24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>19964</td>\n",
       "      <td>19544</td>\n",
       "      <td>19390</td>\n",
       "      <td>19442</td>\n",
       "      <td>19755</td>\n",
       "      <td>20008</td>\n",
       "      <td>...</td>\n",
       "      <td>14535</td>\n",
       "      <td>13955</td>\n",
       "      <td>13712</td>\n",
       "      <td>14372</td>\n",
       "      <td>16392</td>\n",
       "      <td>18253</td>\n",
       "      <td>18355</td>\n",
       "      <td>17157</td>\n",
       "      <td>16089</td>\n",
       "      <td>15146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>162096</td>\n",
       "      <td>160890</td>\n",
       "      <td>160924</td>\n",
       "      <td>158962</td>\n",
       "      <td>163197</td>\n",
       "      <td>165197</td>\n",
       "      <td>...</td>\n",
       "      <td>151681</td>\n",
       "      <td>148210</td>\n",
       "      <td>149373</td>\n",
       "      <td>153728</td>\n",
       "      <td>171318</td>\n",
       "      <td>175893</td>\n",
       "      <td>175858</td>\n",
       "      <td>166342</td>\n",
       "      <td>155411</td>\n",
       "      <td>145988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id  year  month  day      h1      h2      h3      h4      h5      h6  \\\n",
       "0        1  2005      3    6   19964   19544   19390   19442   19755   20008   \n",
       "1        2  2005      3    6  162096  160890  160924  158962  163197  165197   \n",
       "\n",
       "   ...     h15     h16     h17     h18     h19     h20     h21     h22  \\\n",
       "0  ...   14535   13955   13712   14372   16392   18253   18355   17157   \n",
       "1  ...  151681  148210  149373  153728  171318  175893  175858  166342   \n",
       "\n",
       "      h23     h24  \n",
       "0   16089   15146  \n",
       "1  155411  145988  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading actual load values\n",
    "actual_load = pd.read_csv(r\"C:\\Users\\singh\\Desktop\\TUD (All Semesters)\\Courses - Semester 6 (TU Dresden)\\Thesis Work\\Dataset\\GEFCom2012\\GEFCOM2012_Data\\Load\\Load_solution.csv\")\n",
    "actual_load.drop([\"id\",\"weight\"], axis=1, inplace=True)\n",
    "actual_load[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04d9bbc8-9b28-42d1-b6fb-db5a04819f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>h1</td>\n",
       "      <td>19964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>h1</td>\n",
       "      <td>162096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>h1</td>\n",
       "      <td>174901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>h1</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>h1</td>\n",
       "      <td>9061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id  year  month  day hour    load\n",
       "0        1  2005      3    6   h1   19964\n",
       "1        2  2005      3    6   h1  162096\n",
       "2        3  2005      3    6   h1  174901\n",
       "3        4  2005      3    6   h1     528\n",
       "4        5  2005      3    6   h1    9061"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the data into long-format\n",
    "\n",
    "actual_load_long = actual_load.melt(\n",
    "                id_vars=[\"zone_id\",\"year\",\"month\",\"day\"],\n",
    "                value_vars=[f\"h{i}\" for i in range(1, 25)],\n",
    "                var_name=\"hour\",\n",
    "                value_name=\"load\"\n",
    "                        )\n",
    "\n",
    "\n",
    "actual_load_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea343a74-7e29-45b0-9a8b-a289a1574186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>load</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>19964</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>162096</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>174901</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>528</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>9061</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id  year  month  day   hour    load           timestamp\n",
       "0        1  2005      3    6  00:30   19964 2005-03-06 00:30:00\n",
       "1        2  2005      3    6  00:30  162096 2005-03-06 00:30:00\n",
       "2        3  2005      3    6  00:30  174901 2005-03-06 00:30:00\n",
       "3        4  2005      3    6  00:30     528 2005-03-06 00:30:00\n",
       "4        5  2005      3    6  00:30    9061 2005-03-06 00:30:00"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing hour values with interval mid-point\n",
    "\n",
    "# Create a mapping from 'h1' to 'h24' → '00:30' to '23:30'\n",
    "hour_map = {f\"h{i}\": f\"{str(i-1).zfill(2)}:30\" for i in range(1, 25)}\n",
    "\n",
    "# Replace the values using .map()\n",
    "actual_load_long[\"hour\"] = actual_load_long[\"hour\"].map(hour_map)\n",
    "\n",
    "# Creating timestamps using existing information\n",
    "actual_load_long[\"timestamp\"] = pd.to_datetime(\n",
    "    actual_load_long[\"year\"].astype(str) + \"-\" +\n",
    "    actual_load_long[\"month\"].astype(str).str.zfill(2) + \"-\" +\n",
    "    actual_load_long[\"day\"].astype(str).str.zfill(2) + \" \" +\n",
    "    actual_load_long[\"hour\"]\n",
    ")\n",
    "\n",
    "actual_load_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cdaf090c-36ae-4c6a-ac8d-bf0a22602210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-03-06 00:30:00</th>\n",
       "      <td>19964.0</td>\n",
       "      <td>162096.0</td>\n",
       "      <td>174901.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>171157.0</td>\n",
       "      <td>174901.0</td>\n",
       "      <td>4091.0</td>\n",
       "      <td>61215.0</td>\n",
       "      <td>26459.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140417.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>27740.0</td>\n",
       "      <td>74218.0</td>\n",
       "      <td>40411.0</td>\n",
       "      <td>36845.0</td>\n",
       "      <td>268789.0</td>\n",
       "      <td>102241.0</td>\n",
       "      <td>89800.0</td>\n",
       "      <td>1719688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 01:30:00</th>\n",
       "      <td>19544.0</td>\n",
       "      <td>160890.0</td>\n",
       "      <td>173600.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>8697.0</td>\n",
       "      <td>169587.0</td>\n",
       "      <td>173600.0</td>\n",
       "      <td>3971.0</td>\n",
       "      <td>61131.0</td>\n",
       "      <td>25979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137418.0</td>\n",
       "      <td>20466.0</td>\n",
       "      <td>27713.0</td>\n",
       "      <td>73397.0</td>\n",
       "      <td>40408.0</td>\n",
       "      <td>36745.0</td>\n",
       "      <td>267273.0</td>\n",
       "      <td>101374.0</td>\n",
       "      <td>88325.0</td>\n",
       "      <td>1703132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                   1         2         3      4       5         6   \\\n",
       "timestamp                                                                   \n",
       "2005-03-06 00:30:00  19964.0  162096.0  174901.0  528.0  9061.0  171157.0   \n",
       "2005-03-06 01:30:00  19544.0  160890.0  173600.0  499.0  8697.0  169587.0   \n",
       "\n",
       "zone_id                    7       8        9        10  ...        12  \\\n",
       "timestamp                                                ...             \n",
       "2005-03-06 00:30:00  174901.0  4091.0  61215.0  26459.0  ...  140417.0   \n",
       "2005-03-06 01:30:00  173600.0  3971.0  61131.0  25979.0  ...  137418.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2005-03-06 00:30:00  21302.0  27740.0  74218.0  40411.0  36845.0  268789.0   \n",
       "2005-03-06 01:30:00  20466.0  27713.0  73397.0  40408.0  36745.0  267273.0   \n",
       "\n",
       "zone_id                    19       20         21  \n",
       "timestamp                                          \n",
       "2005-03-06 00:30:00  102241.0  89800.0  1719688.0  \n",
       "2005-03-06 01:30:00  101374.0  88325.0  1703132.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivoting to record zone by column\n",
    "actual_load_long = pd.pivot_table(actual_load_long, index=\"timestamp\", columns=\"zone_id\", values=\"load\")\n",
    "actual_load_long[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cac2ac-0c53-44d0-9b38-f0e4fe960961",
   "metadata": {},
   "source": [
    "#### Comparing Time Series Regression With Actual Load Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89d93d-9ff2-44b9-8062-b6c4c97ce675",
   "metadata": {},
   "source": [
    "##### Period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e69f6199-4b9a-43f2-80c1-4969214d0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 1: 0.27518553894682396\n",
      "Average MAPE score for all zones, Period 1: 0.09005387465758358\n",
      "Average RMSE score for all zones, Period 1: 8107.365819103414\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "r2_scores_p1 = []\n",
    "mape_scores_p1 = []\n",
    "rmse_scores_p1 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p1_mean_unlogged.index,i]),np.array(predictions_p1_mean_unlogged.loc[:,predictions_p1_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p1_mean_unlogged.index,i]),np.array(predictions_p1_mean_unlogged.loc[:,predictions_p1_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p1_mean_unlogged.index,i]),np.array(predictions_p1_mean_unlogged.loc[:,predictions_p1_mean_unlogged.columns[i-1]])))\n",
    "\n",
    "    # adding scores to score list\n",
    "    r2_scores_p1.append(r2)\n",
    "    mape_scores_p1.append(mape)\n",
    "    rmse_scores_p1.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 1: {np.mean(r2_scores_p1)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 1: {np.mean(mape_scores_p1)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 1: {np.mean(rmse_scores_p1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68d32d16-6a7b-4990-bfb1-1fb7a913e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7190577847776094,\n",
       " 0.7089290009511293,\n",
       " 0.7089255538296835,\n",
       " -1.7480598408049048,\n",
       " 0.8193506581691473,\n",
       " 0.7282814152107118,\n",
       " 0.7089255538296835,\n",
       " 0.70486150613994,\n",
       " -6.374771929939902,\n",
       " 0.7534339847720513,\n",
       " 0.8205575838638297,\n",
       " 0.7557335686032196,\n",
       " 0.7103436330563887,\n",
       " 0.7511700740147598,\n",
       " 0.7992957229654462,\n",
       " 0.8758137693492368,\n",
       " 0.6642897826021197,\n",
       " 0.8835970572915676,\n",
       " 0.7576423817523699,\n",
       " 0.7563335185023928]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zone 4 and 9 are showing some issues\n",
    "r2_scores_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b2893-ff78-475f-a821-1d0fa3bb444c",
   "metadata": {},
   "source": [
    "##### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19861738-0de7-4670-b4dc-c4eb61b7c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 2: 0.1363698330839401\n",
      "Average MAPE score for all zones, Period 2: 0.0979776554596269\n",
      "Average RMSE score for all zones, Period 2: 8446.908942592518\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p2 = []\n",
    "mape_scores_p2 = []\n",
    "rmse_scores_p2 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p2_mean_unlogged.index,i]),np.array(predictions_p2_mean_unlogged.loc[:,predictions_p2_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p2_mean_unlogged.index,i]),np.array(predictions_p2_mean_unlogged.loc[:,predictions_p2_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p2_mean_unlogged.index,i]),np.array(predictions_p2_mean_unlogged.loc[:,predictions_p2_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p2.append(r2)\n",
    "    mape_scores_p2.append(mape)\n",
    "    rmse_scores_p2.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 2: {np.mean(r2_scores_p2)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 2: {np.mean(mape_scores_p2)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 2: {np.mean(rmse_scores_p2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3523c-c71f-45f5-86b0-771aa324f6c8",
   "metadata": {},
   "source": [
    "##### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "049ca051-ffae-4368-9c92-8325d2ad9dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 3: 0.7727762634560691\n",
      "Average MAPE score for all zones, Period 3: 0.09350283854501222\n",
      "Average RMSE score for all zones, Period 3: 8483.527856562328\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p3 = []\n",
    "mape_scores_p3 = []\n",
    "rmse_scores_p3 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p3_mean_unlogged.index,i]),np.array(predictions_p3_mean_unlogged.loc[:,predictions_p3_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p3_mean_unlogged.index,i]),np.array(predictions_p3_mean_unlogged.loc[:,predictions_p3_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p3_mean_unlogged.index,i]),np.array(predictions_p3_mean_unlogged.loc[:,predictions_p3_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p3.append(r2)\n",
    "    mape_scores_p3.append(mape)\n",
    "    rmse_scores_p3.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 3: {np.mean(r2_scores_p3)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 3: {np.mean(mape_scores_p3)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 3: {np.mean(rmse_scores_p3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09965648-c8d3-463e-8755-36d3a1fa3077",
   "metadata": {},
   "source": [
    "##### Period 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5746384-45c9-4095-9b13-1dbf804dd376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 4: 0.5375143207642463\n",
      "Average MAPE score for all zones, Period 4: 0.09552146057797163\n",
      "Average RMSE score for all zones, Period 4: 7303.21206914267\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p4 = []\n",
    "mape_scores_p4 = []\n",
    "rmse_scores_p4 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p4_mean_unlogged.index,i]),np.array(predictions_p4_mean_unlogged.loc[:,predictions_p4_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p4_mean_unlogged.index,i]),np.array(predictions_p4_mean_unlogged.loc[:,predictions_p4_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p4_mean_unlogged.index,i]),np.array(predictions_p4_mean_unlogged.loc[:,predictions_p4_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p4.append(r2)\n",
    "    mape_scores_p4.append(mape)\n",
    "    rmse_scores_p4.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 4: {np.mean(r2_scores_p4)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 4: {np.mean(mape_scores_p4)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 4: {np.mean(rmse_scores_p4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f01df-b11f-457b-afc0-eb164e54a612",
   "metadata": {},
   "source": [
    "##### Period 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45ebfeb0-2b8d-47c2-b7ea-609474bc8b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 5: 0.8076961578726424\n",
      "Average MAPE score for all zones, Period 5: 0.10418891102547367\n",
      "Average RMSE score for all zones, Period 5: 6660.027118203421\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p5 = []\n",
    "mape_scores_p5 = []\n",
    "rmse_scores_p5 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p5_mean_unlogged.index,i]),np.array(predictions_p5_mean_unlogged.loc[:,predictions_p5_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p5_mean_unlogged.index,i]),np.array(predictions_p5_mean_unlogged.loc[:,predictions_p5_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p5_mean_unlogged.index,i]),np.array(predictions_p5_mean_unlogged.loc[:,predictions_p5_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p5.append(r2)\n",
    "    mape_scores_p5.append(mape)\n",
    "    rmse_scores_p5.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 5: {np.mean(r2_scores_p5)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 5: {np.mean(mape_scores_p5)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 5: {np.mean(rmse_scores_p5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d65ff0-5867-47f1-935e-c47b3e5f2125",
   "metadata": {},
   "source": [
    "##### Period 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9c8e31b-194e-4906-8573-326d606254d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 6: 0.4714400388948642\n",
      "Average MAPE score for all zones, Period 6: 14820.242318577893\n",
      "Average RMSE score for all zones, Period 6: 5299.770766260277\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p6 = []\n",
    "mape_scores_p6 = []\n",
    "rmse_scores_p6 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p6_mean_unlogged.index,i]),np.array(predictions_p6_mean_unlogged.loc[:,predictions_p6_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p6_mean_unlogged.index,i]),np.array(predictions_p6_mean_unlogged.loc[:,predictions_p6_mean_unlogged.columns[i-1]]))\n",
    "    mape = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p6_mean_unlogged.index,i]),np.array(predictions_p6_mean_unlogged.loc[:,predictions_p6_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p6.append(r2)\n",
    "    mape_scores_p6.append(mape)\n",
    "    rmse_scores_p6.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 6: {np.mean(r2_scores_p6)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 6: {np.mean(mape_scores_p6)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 6: {np.mean(rmse_scores_p6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8869a-c4c5-4729-b57c-61e10db2db51",
   "metadata": {},
   "source": [
    "##### Period 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d238f1a-f669-40c8-84f9-777766a412e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 7: 0.8580772662181951\n",
      "Average MAPE score for all zones, Period 7: 0.09588009665710692\n",
      "Average RMSE score for all zones, Period 7: 9258.506987863877\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p7 = []\n",
    "mape_scores_p7 = []\n",
    "rmse_scores_p7 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p7_mean_unlogged.index,i]),np.array(predictions_p7_mean_unlogged.loc[:,predictions_p7_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p7_mean_unlogged.index,i]),np.array(predictions_p7_mean_unlogged.loc[:,predictions_p7_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p7_mean_unlogged.index,i]),np.array(predictions_p7_mean_unlogged.loc[:,predictions_p7_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p7.append(r2)\n",
    "    mape_scores_p7.append(mape)\n",
    "    rmse_scores_p7.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 7: {np.mean(r2_scores_p7)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 7: {np.mean(mape_scores_p7)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 7: {np.mean(rmse_scores_p7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec49f80-5d95-4d88-bfbe-924141caf4e6",
   "metadata": {},
   "source": [
    "##### Period 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14174f8e-39e7-40da-b8f4-2114c62260ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 8: 0.251919090432252\n",
      "Average MAPE score for all zones, Period 8: 0.10834000744050616\n",
      "Average RMSE score for all zones, Period 8: 10320.825613947552\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p8 = []\n",
    "mape_scores_p8 = []\n",
    "rmse_scores_p8 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p8_mean_unlogged.index,i]),np.array(predictions_p8_mean_unlogged.loc[:,predictions_p8_mean_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p8_mean_unlogged.index,i]),np.array(predictions_p8_mean_unlogged.loc[:,predictions_p8_mean_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p8_mean_unlogged.index,i]),np.array(predictions_p8_mean_unlogged.loc[:,predictions_p8_mean_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p8.append(r2)\n",
    "    mape_scores_p8.append(mape)\n",
    "    rmse_scores_p8.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 8: {np.mean(r2_scores_p8)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 8: {np.mean(mape_scores_p8)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 8: {np.mean(rmse_scores_p8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62598243-2648-41b7-a373-b15f389f3d1c",
   "metadata": {},
   "source": [
    "###### Overall Performance on Average, across periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30ac2472-3e8e-4f0b-86f3-550ca62fb9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score across all 8 periods, complete grid: 0.5138723137086292\n",
      "Average MAPE score across all 8 periods, complete grid: 1852.615972927782\n",
      "Average RMSE score across all 8 periods, complete grid: 7985.018146709507\n"
     ]
    }
   ],
   "source": [
    "# Metric averaged across 8 periods, complete grid performance\n",
    "\n",
    "avg_r2_list = []\n",
    "for i in [r2_scores_p1,r2_scores_p2,r2_scores_p3,r2_scores_p4,r2_scores_p5,r2_scores_p6,r2_scores_p7,r2_scores_p8]:\n",
    "    avg_r = np.mean(i)        # averaged across all 20 zones, for a given period\n",
    "    avg_r2_list.append(avg_r)\n",
    "\n",
    "print(f\"Average R2 score across all 8 periods, complete grid: {np.mean(avg_r2_list)}\")\n",
    "\n",
    "avg_mape_list = []\n",
    "for j in [mape_scores_p1,mape_scores_p2,mape_scores_p3,mape_scores_p4,mape_scores_p5,mape_scores_p6,mape_scores_p7,mape_scores_p8]:\n",
    "    avg_m = np.mean(j)        # averaged across all 20 zones, for a given period\n",
    "    avg_mape_list.append(avg_m)\n",
    "\n",
    "print(f\"Average MAPE score across all 8 periods, complete grid: {np.mean(avg_mape_list)}\")\n",
    "\n",
    "avg_rmse_list = []\n",
    "for k in [rmse_scores_p1,rmse_scores_p2,rmse_scores_p3,rmse_scores_p4,rmse_scores_p5,rmse_scores_p6,rmse_scores_p7,rmse_scores_p8]:\n",
    "    avg_rm = np.mean(k)        # averaged across all 20 zones, for a given period\n",
    "    avg_rmse_list.append(avg_rm)\n",
    "\n",
    "print(f\"Average RMSE score across all 8 periods, complete grid: {np.mean(avg_rmse_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77bf980-e5eb-4d89-b669-e9c179af399a",
   "metadata": {},
   "source": [
    "#### Comparing Naive Prediction With Actual Load Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03f431-bb58-40d5-a1ec-05ea3e960ca7",
   "metadata": {},
   "source": [
    "##### Period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de9109cd-4f4c-4c7a-9dc5-aca89f474735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 1: -0.403443635119234\n",
      "Average MAPE score for all zones, Period 1: 0.1751119096892755\n",
      "Average RMSE score for all zones, Period 1: 15805.303177066051\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p1 = []\n",
    "mape_scores_p1 = []\n",
    "rmse_scores_p1 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p1_unlogged.index,i]),np.array(last_cycle_naive_p1_unlogged.loc[:,last_cycle_naive_p1_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p1_unlogged.index,i]),np.array(last_cycle_naive_p1_unlogged.loc[:,last_cycle_naive_p1_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p1_unlogged.index,i]),np.array(last_cycle_naive_p1_unlogged.loc[:,last_cycle_naive_p1_unlogged.columns[i-1]])))\n",
    "\n",
    "    # adding scores to score list\n",
    "    r2_scores_p1.append(r2)\n",
    "    mape_scores_p1.append(mape)\n",
    "    rmse_scores_p1.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 1: {np.mean(r2_scores_p1)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 1: {np.mean(mape_scores_p1)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 1: {np.mean(rmse_scores_p1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fede0af-491d-4503-9458-b603115b34a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.8045817850316563,\n",
       " 0.22020601071801205,\n",
       " 0.22021134777983098,\n",
       " -0.21288627755387135,\n",
       " -0.08485266343471598,\n",
       " 0.18635357864996405,\n",
       " 0.22021134777983098,\n",
       " 0.1067208111758482,\n",
       " -5.270399713829374,\n",
       " 0.3043234098764367,\n",
       " 0.1616939130051499,\n",
       " 0.0384987959159101,\n",
       " -0.11459705037099832,\n",
       " -0.42820074834427,\n",
       " -0.39638026369890045,\n",
       " -0.41540187727136635,\n",
       " -0.712037845142111,\n",
       " -0.35927722881498303,\n",
       " -0.7219497766522796,\n",
       " -0.006526687141136245]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most scores are extremely poor\n",
    "r2_scores_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba0ab9-3050-4a59-aee1-efcc7f6062f4",
   "metadata": {},
   "source": [
    "##### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4bd635a0-f02f-444b-8595-3ee162cdc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 2: -0.7604482328878115\n",
      "Average MAPE score for all zones, Period 2: 0.24201497981319758\n",
      "Average RMSE score for all zones, Period 2: 22595.193372002155\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p2 = []\n",
    "mape_scores_p2 = []\n",
    "rmse_scores_p2 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p2_unlogged.index,i]),np.array(last_cycle_naive_p2_unlogged.loc[:,last_cycle_naive_p2_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p2_unlogged.index,i]),np.array(last_cycle_naive_p2_unlogged.loc[:,last_cycle_naive_p2_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p2_unlogged.index,i]),np.array(last_cycle_naive_p2_unlogged.loc[:,last_cycle_naive_p2_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p2.append(r2)\n",
    "    mape_scores_p2.append(mape)\n",
    "    rmse_scores_p2.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 2: {np.mean(r2_scores_p2)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 2: {np.mean(mape_scores_p2)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 2: {np.mean(rmse_scores_p2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a16e4-fa98-4df1-99e1-44267a108e79",
   "metadata": {},
   "source": [
    "##### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7477774b-92f5-4fc8-bb30-30daad40455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 3: 0.5358353871978386\n",
      "Average MAPE score for all zones, Period 3: 0.12832544176716906\n",
      "Average RMSE score for all zones, Period 3: 12729.16779995972\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p3 = []\n",
    "mape_scores_p3 = []\n",
    "rmse_scores_p3 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p3_unlogged.index,i]),np.array(last_cycle_naive_p3_unlogged.loc[:,last_cycle_naive_p3_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p3_unlogged.index,i]),np.array(last_cycle_naive_p3_unlogged.loc[:,last_cycle_naive_p3_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p3_unlogged.index,i]),np.array(last_cycle_naive_p3_unlogged.loc[:,last_cycle_naive_p3_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p3.append(r2)\n",
    "    mape_scores_p3.append(mape)\n",
    "    rmse_scores_p3.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 3: {np.mean(r2_scores_p3)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 3: {np.mean(mape_scores_p3)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 3: {np.mean(rmse_scores_p3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b87746-897b-4cec-9d96-068e23ed69e0",
   "metadata": {},
   "source": [
    "##### Period 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "831edfe3-4be3-4d03-bdb5-d468ff7e2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 4: -2.4401341249971926\n",
      "Average MAPE score for all zones, Period 4: 0.2265497298883694\n",
      "Average RMSE score for all zones, Period 4: 21212.871729678176\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p4 = []\n",
    "mape_scores_p4 = []\n",
    "rmse_scores_p4 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p4_unlogged.index,i]),np.array(last_cycle_naive_p4_unlogged.loc[:,last_cycle_naive_p4_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p4_unlogged.index,i]),np.array(last_cycle_naive_p4_unlogged.loc[:,last_cycle_naive_p4_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p4_unlogged.index,i]),np.array(last_cycle_naive_p4_unlogged.loc[:,last_cycle_naive_p4_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p4.append(r2)\n",
    "    mape_scores_p4.append(mape)\n",
    "    rmse_scores_p4.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 4: {np.mean(r2_scores_p4)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 4: {np.mean(mape_scores_p4)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 4: {np.mean(rmse_scores_p4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8170722-e358-4d2b-8d1d-2f9cdff1ae77",
   "metadata": {},
   "source": [
    "##### Period 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a958c870-062c-4893-adca-8fe8d6d9cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 5: -0.15845509256449225\n",
      "Average MAPE score for all zones, Period 5: 0.2281669305082108\n",
      "Average RMSE score for all zones, Period 5: 18991.150026154777\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p5 = []\n",
    "mape_scores_p5 = []\n",
    "rmse_scores_p5 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p5_unlogged.index,i]),np.array(last_cycle_naive_p5_unlogged.loc[:,last_cycle_naive_p5_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p5_unlogged.index,i]),np.array(last_cycle_naive_p5_unlogged.loc[:,last_cycle_naive_p5_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p5_unlogged.index,i]),np.array(last_cycle_naive_p5_unlogged.loc[:,last_cycle_naive_p5_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p5.append(r2)\n",
    "    mape_scores_p5.append(mape)\n",
    "    rmse_scores_p5.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 5: {np.mean(r2_scores_p5)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 5: {np.mean(mape_scores_p5)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 5: {np.mean(rmse_scores_p5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda957da-c707-4cd5-a6ec-4c4fefd83d8e",
   "metadata": {},
   "source": [
    "##### Period 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5579468d-f545-49ed-8ccb-c37a8b686cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 6: -0.10384797999226474\n",
      "Average MAPE score for all zones, Period 6: 0.19152103232021125\n",
      "Average RMSE score for all zones, Period 6: 20614.317789472036\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p6 = []\n",
    "mape_scores_p6 = []\n",
    "rmse_scores_p6 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p6_unlogged.index,i]),np.array(last_cycle_naive_p6_unlogged.loc[:,last_cycle_naive_p6_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p6_unlogged.index,i]),np.array(last_cycle_naive_p6_unlogged.loc[:,last_cycle_naive_p6_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p6_unlogged.index,i]),np.array(last_cycle_naive_p6_unlogged.loc[:,last_cycle_naive_p6_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p6.append(r2)\n",
    "    mape_scores_p6.append(mape)\n",
    "    rmse_scores_p6.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 6: {np.mean(r2_scores_p6)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 6: {np.mean(mape_scores_p6)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 6: {np.mean(rmse_scores_p6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199137b1-e50d-49cc-93c9-04aa3d446aca",
   "metadata": {},
   "source": [
    "##### Period 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdffc51f-f689-4a1d-b6ef-cafb09af2e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 7: 0.685169965264994\n",
      "Average MAPE score for all zones, Period 7: 0.13441551148576594\n",
      "Average RMSE score for all zones, Period 7: 14533.344010093784\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p7 = []\n",
    "mape_scores_p7 = []\n",
    "rmse_scores_p7 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p7_unlogged.index,i]),np.array(last_cycle_naive_p7_unlogged.loc[:,last_cycle_naive_p7_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p7_unlogged.index,i]),np.array(last_cycle_naive_p7_unlogged.loc[:,last_cycle_naive_p7_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p7_unlogged.index,i]),np.array(last_cycle_naive_p7_unlogged.loc[:,last_cycle_naive_p7_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p7.append(r2)\n",
    "    mape_scores_p7.append(mape)\n",
    "    rmse_scores_p7.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 7: {np.mean(r2_scores_p7)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 7: {np.mean(mape_scores_p7)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 7: {np.mean(rmse_scores_p7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8857d-9d4c-43dc-a6df-0e9c5eb69924",
   "metadata": {},
   "source": [
    "##### Period 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a09b780b-8ae0-4171-a9bc-c97f49041c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 8: -0.5163474329789117\n",
      "Average MAPE score for all zones, Period 8: 0.1574119195207866\n",
      "Average RMSE score for all zones, Period 8: 13439.366006618406\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p8 = []\n",
    "mape_scores_p8 = []\n",
    "rmse_scores_p8 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[last_cycle_naive_p8_unlogged.index,i]),np.array(last_cycle_naive_p8_unlogged.loc[:,last_cycle_naive_p8_unlogged.columns[i-1]]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[last_cycle_naive_p8_unlogged.index,i]),np.array(last_cycle_naive_p8_unlogged.loc[:,last_cycle_naive_p8_unlogged.columns[i-1]]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[last_cycle_naive_p8_unlogged.index,i]),np.array(last_cycle_naive_p8_unlogged.loc[:,last_cycle_naive_p8_unlogged.columns[i-1]])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p8.append(r2)\n",
    "    mape_scores_p8.append(mape)\n",
    "    rmse_scores_p8.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 8: {np.mean(r2_scores_p8)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 8: {np.mean(mape_scores_p8)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 8: {np.mean(rmse_scores_p8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c863de-4695-4658-9ee4-3b9824ca98b5",
   "metadata": {},
   "source": [
    "###### Overall Performance on Average, across periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87f0ed53-0c41-4721-a5e5-1b22b5fe1ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score across all 8 periods, complete grid: -0.39520889325963426\n",
      "Average MAPE score across all 8 periods, complete grid: 0.18543968187412327\n",
      "Average RMSE score across all 8 periods, complete grid: 17490.08923888064\n"
     ]
    }
   ],
   "source": [
    "# Metric averaged across 8 periods, complete grid performance\n",
    "\n",
    "avg_r2_list = []\n",
    "for i in [r2_scores_p1,r2_scores_p2,r2_scores_p3,r2_scores_p4,r2_scores_p5,r2_scores_p6,r2_scores_p7,r2_scores_p8]:\n",
    "    avg_r = np.mean(i)        # averaged across all 20 zones, for a given period\n",
    "    avg_r2_list.append(avg_r)\n",
    "\n",
    "print(f\"Average R2 score across all 8 periods, complete grid: {np.mean(avg_r2_list)}\")\n",
    "\n",
    "avg_mape_list = []\n",
    "for j in [mape_scores_p1,mape_scores_p2,mape_scores_p3,mape_scores_p4,mape_scores_p5,mape_scores_p6,mape_scores_p7,mape_scores_p8]:\n",
    "    avg_m = np.mean(j)        # averaged across all 20 zones, for a given period\n",
    "    avg_mape_list.append(avg_m)\n",
    "\n",
    "print(f\"Average MAPE score across all 8 periods, complete grid: {np.mean(avg_mape_list)}\")\n",
    "\n",
    "avg_rmse_list = []\n",
    "for k in [rmse_scores_p1,rmse_scores_p2,rmse_scores_p3,rmse_scores_p4,rmse_scores_p5,rmse_scores_p6,rmse_scores_p7,rmse_scores_p8]:\n",
    "    avg_rm = np.mean(k)        # averaged across all 20 zones, for a given period\n",
    "    avg_rmse_list.append(avg_rm)\n",
    "\n",
    "print(f\"Average RMSE score across all 8 periods, complete grid: {np.mean(avg_rmse_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781bbca-d0a8-4110-b343-480fdaa00fde",
   "metadata": {},
   "source": [
    "> The error rate (MAPE) has decreased by approximately 47% relative to the original (naive) error rate, when time series regression is used.\n",
    "\n",
    "> <b>The error rate (RMSE) has decreased by approximately 51.7% relative to the original (naive) error rate, when time series regression is used.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ee3e9-3547-4858-919b-f18e500322e7",
   "metadata": {},
   "source": [
    "#### Comparing Competition's Benchmark Values With Actual Load Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a1da119-6eea-4469-a51b-761f6218ffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>...</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "      <th>h24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>20505</td>\n",
       "      <td>19445</td>\n",
       "      <td>19373</td>\n",
       "      <td>18833</td>\n",
       "      <td>19962</td>\n",
       "      <td>...</td>\n",
       "      <td>14333</td>\n",
       "      <td>13606</td>\n",
       "      <td>14009</td>\n",
       "      <td>15133</td>\n",
       "      <td>16097</td>\n",
       "      <td>16949</td>\n",
       "      <td>16895</td>\n",
       "      <td>16322</td>\n",
       "      <td>14969</td>\n",
       "      <td>14016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>167016</td>\n",
       "      <td>163275</td>\n",
       "      <td>164618</td>\n",
       "      <td>164731</td>\n",
       "      <td>165840</td>\n",
       "      <td>...</td>\n",
       "      <td>145182</td>\n",
       "      <td>140364</td>\n",
       "      <td>141993</td>\n",
       "      <td>148293</td>\n",
       "      <td>151031</td>\n",
       "      <td>158234</td>\n",
       "      <td>162813</td>\n",
       "      <td>158044</td>\n",
       "      <td>148985</td>\n",
       "      <td>140408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>180211</td>\n",
       "      <td>176174</td>\n",
       "      <td>177624</td>\n",
       "      <td>177745</td>\n",
       "      <td>178942</td>\n",
       "      <td>...</td>\n",
       "      <td>156652</td>\n",
       "      <td>151453</td>\n",
       "      <td>153210</td>\n",
       "      <td>160008</td>\n",
       "      <td>162963</td>\n",
       "      <td>170735</td>\n",
       "      <td>175675</td>\n",
       "      <td>170530</td>\n",
       "      <td>160756</td>\n",
       "      <td>151501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>530</td>\n",
       "      <td>496</td>\n",
       "      <td>489</td>\n",
       "      <td>460</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>497</td>\n",
       "      <td>472</td>\n",
       "      <td>479</td>\n",
       "      <td>512</td>\n",
       "      <td>535</td>\n",
       "      <td>542</td>\n",
       "      <td>552</td>\n",
       "      <td>536</td>\n",
       "      <td>468</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8585</td>\n",
       "      <td>8346</td>\n",
       "      <td>8564</td>\n",
       "      <td>8638</td>\n",
       "      <td>8793</td>\n",
       "      <td>...</td>\n",
       "      <td>6835</td>\n",
       "      <td>6486</td>\n",
       "      <td>6679</td>\n",
       "      <td>7343</td>\n",
       "      <td>7723</td>\n",
       "      <td>8347</td>\n",
       "      <td>8536</td>\n",
       "      <td>7856</td>\n",
       "      <td>6816</td>\n",
       "      <td>5974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  zone_id  year  month  day      h1      h2      h3      h4      h5  ...  \\\n",
       "0   1        1  2005      3    6   20505   19445   19373   18833   19962  ...   \n",
       "1   2        2  2005      3    6  167016  163275  164618  164731  165840  ...   \n",
       "2   3        3  2005      3    6  180211  176174  177624  177745  178942  ...   \n",
       "3   4        4  2005      3    6     530     496     489     460     492  ...   \n",
       "4   5        5  2005      3    6    8585    8346    8564    8638    8793  ...   \n",
       "\n",
       "      h15     h16     h17     h18     h19     h20     h21     h22     h23  \\\n",
       "0   14333   13606   14009   15133   16097   16949   16895   16322   14969   \n",
       "1  145182  140364  141993  148293  151031  158234  162813  158044  148985   \n",
       "2  156652  151453  153210  160008  162963  170735  175675  170530  160756   \n",
       "3     497     472     479     512     535     542     552     536     468   \n",
       "4    6835    6486    6679    7343    7723    8347    8536    7856    6816   \n",
       "\n",
       "      h24  \n",
       "0   14016  \n",
       "1  140408  \n",
       "2  151501  \n",
       "3     415  \n",
       "4    5974  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading benchmark load\n",
    "\n",
    "load_bench = pd.read_csv(r\"C:\\Users\\singh\\Desktop\\TUD (All Semesters)\\Courses - Semester 6 (TU Dresden)\\Thesis Work\\Dataset\\GEFCom2012\\GEFCOM2012_Data\\Load\\Load_benchmark.csv\")\n",
    "load_bench.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b55a47b-a6f0-4925-9746-cb8007f021d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>load</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>20505</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>167016</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>180211</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>530</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>00:30</td>\n",
       "      <td>8585</td>\n",
       "      <td>2005-03-06 00:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id  year  month  day   hour    load           timestamp\n",
       "0        1  2005      3    6  00:30   20505 2005-03-06 00:30:00\n",
       "1        2  2005      3    6  00:30  167016 2005-03-06 00:30:00\n",
       "2        3  2005      3    6  00:30  180211 2005-03-06 00:30:00\n",
       "3        4  2005      3    6  00:30     530 2005-03-06 00:30:00\n",
       "4        5  2005      3    6  00:30    8585 2005-03-06 00:30:00"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the data into long-format\n",
    "\n",
    "load_bench = load_bench.melt(\n",
    "                id_vars=[\"zone_id\",\"year\",\"month\",\"day\"],\n",
    "                value_vars=[f\"h{i}\" for i in range(1, 25)],\n",
    "                var_name=\"hour\",\n",
    "                value_name=\"load\"\n",
    "                        )\n",
    "\n",
    "\n",
    "# Replacing hour values with interval mid-point\n",
    "\n",
    "# Replace the values using .map()\n",
    "load_bench[\"hour\"] = load_bench[\"hour\"].map(hour_map)\n",
    "\n",
    "# Creating timestamps using existing information\n",
    "load_bench[\"timestamp\"] = pd.to_datetime(\n",
    "    load_bench[\"year\"].astype(str) + \"-\" +\n",
    "    load_bench[\"month\"].astype(str).str.zfill(2) + \"-\" +\n",
    "    load_bench[\"day\"].astype(str).str.zfill(2) + \" \" +\n",
    "    load_bench[\"hour\"]\n",
    ")\n",
    "\n",
    "load_bench.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e582badf-2d84-45b0-9c80-658577dfc835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zone_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-03-06 00:30:00</th>\n",
       "      <td>20505.0</td>\n",
       "      <td>167016.0</td>\n",
       "      <td>180211.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>8585.0</td>\n",
       "      <td>175595.0</td>\n",
       "      <td>180211.0</td>\n",
       "      <td>4053.0</td>\n",
       "      <td>70026.0</td>\n",
       "      <td>23703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144092.0</td>\n",
       "      <td>21404.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>70867.0</td>\n",
       "      <td>36580.0</td>\n",
       "      <td>33450.0</td>\n",
       "      <td>243806.0</td>\n",
       "      <td>91796.0</td>\n",
       "      <td>86322.0</td>\n",
       "      <td>1695779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-06 01:30:00</th>\n",
       "      <td>19445.0</td>\n",
       "      <td>163275.0</td>\n",
       "      <td>176174.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>8346.0</td>\n",
       "      <td>171615.0</td>\n",
       "      <td>176174.0</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>70123.0</td>\n",
       "      <td>22995.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138805.0</td>\n",
       "      <td>20139.0</td>\n",
       "      <td>23888.0</td>\n",
       "      <td>67545.0</td>\n",
       "      <td>36716.0</td>\n",
       "      <td>32688.0</td>\n",
       "      <td>244966.0</td>\n",
       "      <td>86833.0</td>\n",
       "      <td>82373.0</td>\n",
       "      <td>1655145.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "zone_id                   1         2         3      4       5         6   \\\n",
       "timestamp                                                                   \n",
       "2005-03-06 00:30:00  20505.0  167016.0  180211.0  530.0  8585.0  175595.0   \n",
       "2005-03-06 01:30:00  19445.0  163275.0  176174.0  496.0  8346.0  171615.0   \n",
       "\n",
       "zone_id                    7       8        9        10  ...        12  \\\n",
       "timestamp                                                ...             \n",
       "2005-03-06 00:30:00  180211.0  4053.0  70026.0  23703.0  ...  144092.0   \n",
       "2005-03-06 01:30:00  176174.0  3844.0  70123.0  22995.0  ...  138805.0   \n",
       "\n",
       "zone_id                   13       14       15       16       17        18  \\\n",
       "timestamp                                                                    \n",
       "2005-03-06 00:30:00  21404.0  25238.0  70867.0  36580.0  33450.0  243806.0   \n",
       "2005-03-06 01:30:00  20139.0  23888.0  67545.0  36716.0  32688.0  244966.0   \n",
       "\n",
       "zone_id                   19       20         21  \n",
       "timestamp                                         \n",
       "2005-03-06 00:30:00  91796.0  86322.0  1695779.0  \n",
       "2005-03-06 01:30:00  86833.0  82373.0  1655145.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivoting to record zone by column\n",
    "load_bench = pd.pivot_table(load_bench, index=\"timestamp\", columns=\"zone_id\", values=\"load\")\n",
    "load_bench[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0e3f3-74ee-4777-a135-2802fe7a336f",
   "metadata": {},
   "source": [
    "##### Period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b325616-cbba-441f-a2ea-4358dd11b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 1: 0.7843876695118762\n",
      "Average MAPE score for all zones, Period 1: 0.05993021699568011\n",
      "Average RMSE score for all zones, Period 1: 5698.5266936622\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p1 = []\n",
    "mape_scores_p1 = []\n",
    "rmse_scores_p1 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p1_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p1_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p1_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p1_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p1_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p1_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p1.append(r2)\n",
    "    mape_scores_p1.append(mape)\n",
    "    rmse_scores_p1.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 1: {np.mean(r2_scores_p1)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 1: {np.mean(mape_scores_p1)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 1: {np.mean(rmse_scores_p1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd4661-8444-4953-806c-f262246bf5fb",
   "metadata": {},
   "source": [
    "##### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24d69f08-94ab-4870-8f3a-03aa35bfff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 2: 0.7670102016469259\n",
      "Average MAPE score for all zones, Period 2: 0.07011818431947027\n",
      "Average RMSE score for all zones, Period 2: 6212.343813248906\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p2 = []\n",
    "mape_scores_p2 = []\n",
    "rmse_scores_p2 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p2_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p2_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p2_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p2_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p2_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p2_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p2.append(r2)\n",
    "    mape_scores_p2.append(mape)\n",
    "    rmse_scores_p2.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 2: {np.mean(r2_scores_p2)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 2: {np.mean(mape_scores_p2)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 2: {np.mean(rmse_scores_p2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a2b36-a35e-4145-baa6-a6cfa7fde5e5",
   "metadata": {},
   "source": [
    "##### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92f5f96b-eedd-4b25-be44-b684f848df67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 3: 0.8408390776386794\n",
      "Average MAPE score for all zones, Period 3: 0.06986351198380902\n",
      "Average RMSE score for all zones, Period 3: 6695.382053205253\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p3 = []\n",
    "mape_scores_p3 = []\n",
    "rmse_scores_p3 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p3_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p3_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p3_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p3_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p3_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p3_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p3.append(r2)\n",
    "    mape_scores_p3.append(mape)\n",
    "    rmse_scores_p3.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 3: {np.mean(r2_scores_p3)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 3: {np.mean(mape_scores_p3)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 3: {np.mean(rmse_scores_p3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986583a9-775a-4496-9ff7-4c78b720c1dd",
   "metadata": {},
   "source": [
    "##### Period 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a293b3b1-428c-4ec6-8f33-c10635cdf3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 4: 0.4436922037267463\n",
      "Average MAPE score for all zones, Period 4: 0.10292999439807642\n",
      "Average RMSE score for all zones, Period 4: 7866.08314636025\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p4 = []\n",
    "mape_scores_p4 = []\n",
    "rmse_scores_p4 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p4_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p4_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p4_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p4_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p4_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p4_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p4.append(r2)\n",
    "    mape_scores_p4.append(mape)\n",
    "    rmse_scores_p4.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 4: {np.mean(r2_scores_p4)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 4: {np.mean(mape_scores_p4)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 4: {np.mean(rmse_scores_p4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e0fb2-3e83-4b4e-b2d7-595d23da5f94",
   "metadata": {},
   "source": [
    "##### Period 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71f154c9-b9f5-49d0-ab9c-faaff7b82f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 5: 0.3605287919423327\n",
      "Average MAPE score for all zones, Period 5: 0.10270817944634048\n",
      "Average RMSE score for all zones, Period 5: 6441.805707461544\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p5 = []\n",
    "mape_scores_p5 = []\n",
    "rmse_scores_p5 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p5_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p5_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p5_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p5_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p5_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p5_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p5.append(r2)\n",
    "    mape_scores_p5.append(mape)\n",
    "    rmse_scores_p5.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 5: {np.mean(r2_scores_p5)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 5: {np.mean(mape_scores_p5)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 5: {np.mean(rmse_scores_p5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8dba46-db1b-44b8-afe1-10376d81a39e",
   "metadata": {},
   "source": [
    "##### Period 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1256bebd-e2aa-4e5c-b4b4-ab3a5f93888b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 6: 0.5734876577895001\n",
      "Average MAPE score for all zones, Period 6: 0.11750389336898162\n",
      "Average RMSE score for all zones, Period 6: 9385.092514092286\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p6 = []\n",
    "mape_scores_p6 = []\n",
    "rmse_scores_p6 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p6_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p6_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p6_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p6_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p6_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p6_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p6.append(r2)\n",
    "    mape_scores_p6.append(mape)\n",
    "    rmse_scores_p6.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 6: {np.mean(r2_scores_p6)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 6: {np.mean(mape_scores_p6)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 6: {np.mean(rmse_scores_p6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db97477-d026-422c-8099-5e5629088932",
   "metadata": {},
   "source": [
    "##### Period 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1db0092-6924-409a-9f1c-88cdbf944fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 7: 0.9163187319055831\n",
      "Average MAPE score for all zones, Period 7: 0.07326753758533004\n",
      "Average RMSE score for all zones, Period 7: 6190.742612735311\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p7 = []\n",
    "mape_scores_p7 = []\n",
    "rmse_scores_p7 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p7_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p7_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p7_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p7_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p7_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p7_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p7.append(r2)\n",
    "    mape_scores_p7.append(mape)\n",
    "    rmse_scores_p7.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 7: {np.mean(r2_scores_p7)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 7: {np.mean(mape_scores_p7)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 7: {np.mean(rmse_scores_p7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf41cc4-b075-4179-950b-1584b8f875d6",
   "metadata": {},
   "source": [
    "##### Period 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7b3fec38-3b73-4513-abc3-963bfb76c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score for all zones, Period 8: 0.4237862559810378\n",
      "Average MAPE score for all zones, Period 8: 0.09115063921173688\n",
      "Average RMSE score for all zones, Period 8: 8393.01873850579\n"
     ]
    }
   ],
   "source": [
    "# Initiating empty lists\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "r2_scores_p8 = []\n",
    "mape_scores_p8 = []\n",
    "rmse_scores_p8 = []\n",
    "\n",
    "for i in range(1,21,1):\n",
    "    # calculating score metrics for each zone 'i'\n",
    "    r2 = r2_score(np.array(actual_load_long.loc[predictions_p8_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p8_mean_unlogged.index,i]))\n",
    "    mape = mean_absolute_percentage_error(np.array(actual_load_long.loc[predictions_p8_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p8_mean_unlogged.index,i]))\n",
    "    rmse = np.sqrt(mean_squared_error(np.array(actual_load_long.loc[predictions_p8_mean_unlogged.index,i]),np.array(load_bench.loc[predictions_p8_mean_unlogged.index,i])))\n",
    "    \n",
    "    # adding scores to score list\n",
    "    r2_scores_p8.append(r2)\n",
    "    mape_scores_p8.append(mape)\n",
    "    rmse_scores_p8.append(rmse)\n",
    "\n",
    "print(f\"Average R2 score for all zones, Period 8: {np.mean(r2_scores_p8)}\")\n",
    "print(f\"Average MAPE score for all zones, Period 8: {np.mean(mape_scores_p8)}\")\n",
    "print(f\"Average RMSE score for all zones, Period 8: {np.mean(rmse_scores_p8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2c27e-a1a9-42cb-8979-916e59f2d573",
   "metadata": {},
   "source": [
    "###### Overall Performance on Average, across periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7a8e19f5-2781-478e-a5a8-5ea763ef2327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score across all 8 periods, complete grid: 0.6387563237678352\n",
      "Average MAPE score across all 8 periods, complete grid: 0.08593401966367811\n",
      "Average RMSE score across all 8 periods, complete grid: 7110.374409908943\n"
     ]
    }
   ],
   "source": [
    "# Metric averaged across 8 periods, complete grid performance\n",
    "\n",
    "avg_r2_list = []\n",
    "for i in [r2_scores_p1,r2_scores_p2,r2_scores_p3,r2_scores_p4,r2_scores_p5,r2_scores_p6,r2_scores_p7,r2_scores_p8]:\n",
    "    avg_r = np.mean(i)        # averaged across all 20 zones, for a given period\n",
    "    avg_r2_list.append(avg_r)\n",
    "\n",
    "print(f\"Average R2 score across all 8 periods, complete grid: {np.mean(avg_r2_list)}\")\n",
    "\n",
    "avg_mape_list = []\n",
    "for j in [mape_scores_p1,mape_scores_p2,mape_scores_p3,mape_scores_p4,mape_scores_p5,mape_scores_p6,mape_scores_p7,mape_scores_p8]:\n",
    "    avg_m = np.mean(j)        # averaged across all 20 zones, for a given period\n",
    "    avg_mape_list.append(avg_m)\n",
    "\n",
    "print(f\"Average MAPE score across all 8 periods, complete grid: {np.mean(avg_mape_list)}\")\n",
    "\n",
    "avg_rmse_list = []\n",
    "for k in [rmse_scores_p1,rmse_scores_p2,rmse_scores_p3,rmse_scores_p4,rmse_scores_p5,rmse_scores_p6,rmse_scores_p7,rmse_scores_p8]:\n",
    "    avg_rm = np.mean(k)        # averaged across all 20 zones, for a given period\n",
    "    avg_rmse_list.append(avg_rm)\n",
    "\n",
    "print(f\"Average RMSE score across all 8 periods, complete grid: {np.mean(avg_rmse_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60291f7-dd69-45e5-91a6-d31195d3e591",
   "metadata": {},
   "source": [
    "> !For benchmarked values, error reduced by 53.5% compared to naive method (MAPE)!\n",
    "\n",
    "> !<b>For benchmarked values, error reduced by 59.3% compared to naive method (RMSE)</b>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acaf51e-4c1b-4ec7-a1b3-54860d806547",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Compared to competition benchmark, error i.e. rmse increased from 7110.374409908943 to 8110"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
